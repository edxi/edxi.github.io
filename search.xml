<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Shadowsocks+Privoxy+Squid+GFWlist]]></title>
    <url>%2F2018%2F07%2F09%2FShadowsocks_Privoxy_Squid_GFWlist%2F</url>
    <content type="text"><![CDATA[不要被标题这一串软件名字迷惑，这篇博客讲的内容无非就是下面这个图”(￣y▽,￣)╭ “ 最终为了解决内网服务器通过http方式代理访问不同的网站，比如，docker存在国内镜像，那么就直接代理访问，k8s的pause容器须要访问gcr.io，那么就会通过GFWlist再squid规则里指向上级代理privoxy，再通过shadowsocks访问出去。 下面直接看各个软件的配置方法 Shadowsocks 服务器端和客户端的配置一样，只是再json文件里把server写成自己的IP就行了，不赘述，详细配置包括打开fast_open和优化等查看Shadowsocks官方网站[1]这段配置方法引用博客CentOS 7 安装使用Shadowsocks客户端[2] 安装Shadowsocks 安装epel源、安装pip包管理 12sudo yum -y install epel-releasesudo yum -y install python-pip 安装Shadowsocks客户端 1sudo pip install shadowsocks 配置Shadowsocks连接 新建配置文件、默认不存在 12sudo mkdir /etc/shadowsockssudo vi /etc/shadowsocks/shadowsocks.json 添加配置信息：前提是需要有ss服务器的地址、端口等信息 1234567891011&#123; "server":"x.x.x.x", # Shadowsocks服务器地址 "server_port":1035, # Shadowsocks服务器端口 "local_address": "127.0.0.1", # 本地IP "local_port":1080, # 本地端口 "password":"password", # Shadowsocks连接密码 "timeout":300, # 等待超时时间 "method":"aes-256-cfb", # 加密方式 "fast_open": false, # true或false。开启fast_open以降低延迟，但要求Linux内核在3.7+ "workers": 1 #工作线程数 &#125; 配置自启动 新建启动脚本文件/etc/systemd/system/shadowsocks.service，内容如下： 1234567[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/sslocal -c /etc/shadowsocks/shadowsocks.json[Install]WantedBy=multi-user.target 启动Shadowsocks服务 123systemctl enable shadowsocks.servicesystemctl start shadowsocks.servicesystemctl status shadowsocks.service 验证Shadowsocks客户端服务是否正常运行 1curl --socks5 127.0.0.1:1080 http://httpbin.org/ip Shadowsock客户端服务已正常运行，则结果如下： 123&#123; "origin": "x.x.x.x" #你的Shadowsock服务器IP&#125; 安装配置privoxy 安装privoxy 1234yum install privoxy -ysystemctl enable privoxysystemctl start privoxysystemctl status privoxy 配置privoxy 修改配置文件/etc/privoxy/config 12listen-address 127.0.0.1:8118 # 8118 是默认端口，不用改forward-socks5t / 127.0.0.1:1080 . #转发到本地端口，注意最后有个点 设置http、https代理 12345678910# vi /etc/profile 在最后添加如下信息PROXY_HOST=127.0.0.1export all_proxy=http://$PROXY_HOST:8118export ftp_proxy=http://$PROXY_HOST:8118export http_proxy=http://$PROXY_HOST:8118export https_proxy=http://$PROXY_HOST:8118export no_proxy=localhost,172.16.0.0/16,192.168.0.0/16.,127.0.0.1,10.10.0.0/16# 重载环境变量source /etc/profile 测试代理 12345678910111213141516[root@aniu-k8s ~]# curl -I www.google.com HTTP/1.1 200 OKDate: Fri, 26 Jan 2018 05:32:37 GMTExpires: -1Cache-Control: private, max-age=0Content-Type: text/html; charset=ISO-8859-1P3P: CP="This is not a P3P policy! See g.co/p3phelp for more info."Server: gwsX-XSS-Protection: 1; mode=blockX-Frame-Options: SAMEORIGINSet-Cookie: 1P_JAR=2018-01-26-05; expires=Sun, 25-Feb-2018 05:32:37 GMT; path=/; domain=.google.comSet-Cookie: NID=122=PIiGck3gwvrrJSaiwkSKJ5UrfO4WtAO80T4yipOx4R4O0zcgOEdvsKRePWN1DFM66g8PPF4aouhY4JIs7tENdRm7H9hkq5xm4y1yNJ-sZzwVJCLY_OK37sfI5LnSBtb7; expires=Sat, 28-Jul-2018 05:32:37 GMT; path=/; domain=.google.com; HttpOnlyTransfer-Encoding: chunkedAccept-Ranges: noneVary: Accept-EncodingProxy-Connection: keep-alive 取消使用代理 1while read var; do unset $var; done &lt; &lt;(env | grep -i proxy | awk -F= '&#123;print $1&#125;') 设置squid使用GFWlist 参考GFWList 兼容 Squid[3] 使用这个gist的脚本下载GFWlist生成域名的regex列表 /etc/squid/squid.conf 里增加 12345acl gfwlist dstdom_regex &quot;/etc/squid/gfw.url_regex.lst&quot;cache_peer 127.0.0.1 parent 8118 0 no-query name=privoxycache_peer_access privoxy allow allnever_direct allow gfwlist 至此代理服务器已经配置完毕，至于客户端如何配置http proxy和这里就没啥关系了~ 1.Shadowsocks官方网站 ↩2.CentOS 7 安装使用Shadowsocks客户端 ↩3.GFWList 兼容 Squid ↩]]></content>
      <categories>
        <category>学习</category>
        <category>Proxy</category>
      </categories>
      <tags>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-machine使用vSphere驱动(转)]]></title>
    <url>%2F2018%2F07%2F09%2FDockerMachine_vSphere%2F</url>
    <content type="text"><![CDATA[在使用docker-machine的时候，尝试了vSphere driver。Docker的vSphere Driver官方文档[1]比较晦涩，只是列出了支持的参数及其对应的环境变量。这里参照VMware BLOGS的一篇博客[2]作为例子测试通过。 顺便这里提一下，VMware也有自己的容器解决方案，叫VIC，每个容器都创建一个VM，通过VCH来模拟容器主机，Admiral来管理，当然还集成了热门的Harbor作为registry，PhotonOS作为dockerOS。可以到官网上尝试下Hands-on Lab[3]。 docker-machine安装windows和macos就只要直接安装docker会带上，一般问题不大。之所以这里须要提一下，是因为linux上或者须要直接到官方github release页面下载的话，会涉及到墙的问题，当然可以用代理解决，如果不想用代理，那就须要把aws s3服务器在本地Hosts上指定成香港的，如下：123456789[root@docker ~]# echo '219.76.4.4 github-cloud.s3.amazonaws.com' &gt;&gt; /etc/hosts[root@docker ~]# curl -L https://github.com/docker/machine/releases/download/v0.15.0/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp;&gt; chmod +x /tmp/docker-machine &amp;&amp;&gt; sudo cp /tmp/docker-machine /usr/local/bin/docker-machine % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 617 0 617 0 0 701 0 --:--:-- --:--:-- --:--:-- 701100 26.8M 100 26.8M 0 0 328k 0 0:01:23 0:01:23 --:--:-- 523k docker-machine创建vm为了方便解释，这里直接把测试使用的环境变量罗列解释一下：12345678export VSPHERE_VCENTER='hpshvcenter02.vpcsh.com.cn' # vCenter IP/FQDNexport VSPHERE_USERNAME='administrator@vsphere.local' # vCenter user export VSPHERE_PASSWORD='0!MoneyGomyHome' # vCenter user password export VSPHERE_NETWORK='107' # PortGroup 这个网段要有DHCP，否则没法连上管理这个DOCKER MACHINE，这个有bug，必须要在docker-machine命令里使用参数export VSPHERE_DATASTORE='SS8400/8400-1t' # Datastoreexport VSPHERE_DATACENTER='SHVPClab' # Datacenter name export VSPHERE_FOLDER='LabVM/labdockervm' # VM folderexport VSPHERE_HOSTSYSTEM='SHVPClab/*' # could be ommited if DRS, cluster name (inside the datacenter) 可以看到，上面除了VSPHERE_NETWORK，其他环境变量也就直接用好了，用起来都挺正常的。至于DHCP，这个我不知道有什么其他办法可以破，貌似docker-machine也没有参数可以在创建machine的时候指定IP的。 我引用的博客里还使用了docker-machine的swarm参数直接生成swarm cluster，这里就不再赘述了。 管理docker-machine这里不罗嗦了，可以直接参看docker-machine的官方文档。 下面直接看下使用了vSphere环境变量后创建的效果。 1234567891011121314151617181920212223242526admin@labdocker:~$ docker-machine create -d vmwarevsphere --vmwarevsphere-network="107" testvmRunning pre-create checks...Creating machine...(testvm) Copying /home/admin/.docker/machine/cache/boot2docker.iso to /home/admin/.docker/machine/machines/testvm/boot2docker.iso. ..(testvm) Generating SSH Keypair...(testvm) Creating VM...(testvm) Uploading Boot2docker ISO ...(testvm) adding network: 107(testvm) adding network: 107(testvm) Reconfiguring VM(testvm) Waiting for VMware Tools to come online...(testvm) Provisioning certs and ssh keys...Waiting for machine to be running, this may take a few minutes...Detecting operating system of created instance...Waiting for SSH to be available...Detecting the provisioner...Provisioning with boot2docker...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon...Checking connection to Docker...Docker is up and running!To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env testvmadmin@labdocker:~$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORStestvm - vmwarevsphere Running tcp://10.252.7.176:2376 v18.05.0-ce 然而，DHCP因为可能会分配vm新的IP，这就会导致下面这个报错。 123admin@labdocker:~$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORStestvm - vmwarevsphere Running tcp://10.252.7.175:2376 Unknown Unable to query docker version: Get https: //10.252.7.175:2376/v1.15/version: x509: certificate is valid for 10.252.7.176, not 10.252.7.175 这也属于比较常见的问题，通过重新生成连接证书来解决。 12345678admin@labdocker:~$ docker-machine regenerate-certs testvmRegenerate TLS machine certs? Warning: this is irreversible. (y/n): yRegenerating TLS certificatesWaiting for SSH to be available...Detecting the provisioner...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon... 其他使用下来也都一切正常，用完删掉，over了事~（毕竟docker-machine还是作为测试环境比较好，正式环境最好还是上文首VIC这类方案比较好） 12345admin@labdocker:~$ docker-machine rm testvmAbout to remove testvmWARNING: This action will delete both local reference and remote instance.Are you sure? (y/n): ySuccessfully removed testvm 1.Docker machine driver VMware vSphere ↩2.How to use docker-machine in conjunction with the vSphere driver ↩3.vSphere Integrated Containers ↩]]></content>
      <categories>
        <category>学习</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>VMware</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Nexus自建Yum Repository代理]]></title>
    <url>%2F2018%2F04%2F16%2FNexusYum%2F</url>
    <content type="text"><![CDATA[以往为了让内网服务器使用Yum，自建了Yum服务器，大致就是一个apache指向自建的repository目录，然后使用yum-util里的reposync更新rpm（当然也可以手动下载后放到repo目录），再使用createrepo来创建metadata。虽说可以实现，但是也存在不少不便： repo目录日趋庞大 EPEL这样的repo没法下载 同时维护centos7和centos6这样多个版本比较麻烦 只能crontab定期更新，repo内容可能会滞后 最近使Sonatype Nexus的时候发现可以支持Yum Repository，官方博客也早在去年八月就发布了这个功能[1]，通过这个新功能，使得自建的repo可以解决这些困难着实解决了上面这些困难，这里简单介绍下Nexus服务器自建Yum Repository代理的过程。 Nexus的安装和配置过程都比较简单，当然Nexus的功能远不限于此，它提供了当下最流行的库支持（Maven/Java, npm, NuGet, RubyGems, Docker, P2, OBR, APT, YUM 等等），也支持cluster，还提供rest API和基于OSGi的bundle开发。我这里只是让它小露一手而已~附《绿巨人击倒奚有米》的动图，嘿嘿(o゜▽゜)o☆ 安装Nexus官方文档[2]的安装过程并不复杂，我这里简单罗列了使用CentOS7安装的步骤：123456789101112131415161718192021222324252627282930313233343536373839404142# 确保安装了JRE 8$ java -versionopenjdk version "1.8.0_161"OpenJDK Runtime Environment (build 1.8.0_161-b14)OpenJDK 64-Bit Server VM (build 25.161-b14, mixed mode)# 建议创建nexus用户，并设置该用户File Handle Limits$ sudo useradd nexus$ sudo echo "nexus - nofile 65536" &gt;&gt; /etc/security/limits.conf# 下载并解压nexus到/opt目录，并设置nexus用户权限$ wget https://download.sonatype.com/nexus/3/latest-unix.tar.gz$ sudo tar -xzvf latest-unix.tar.gz -C /opt$ sudo mv /opt/nexus* /opt/nexus$ sudo chown -R nexus:nexus /opt/nexus /opt/sonatype-work/# 设置服务启动用户$ sudo echo 'run_as_user="nexus"' &gt; /opt/nexus/bin/nexus.rc# 这里使用systemd管理服务$ sudo cat &lt;&lt;EOF &gt;/etc/systemd/system/nexus.service[Unit]Description=nexus serviceAfter=network.target [Service]Type=forkingExecStart=/opt/nexus/bin/nexus startExecStop=/opt/nexus/bin/nexus stopUser=nexusRestart=on-abort [Install]WantedBy=multi-user.targetEOF$ sudo systemctl daemon-reload$ sudo systemctl enable nexus.service$ sudo systemctl start nexus.service# 最后，查看log了解服务运行状态$ tail -f /opt/sonatype-work/nexus3/log/nexus.log Docker方式运行Nexus另一种方式是使用docker运行，可以参考官方的docker github[3]，列举命令如下：1234567891011121314151617181920212223# 后台运行并映射8081端口，每次随主机启动$ docker run -d -p 8081:8081 --restart=always --name nexus sonatype/nexus3# 查看运行状态$ docker logs -f nexus# 传递环境变量，调整JAVA参数$ docker run -d -p 8081:8081 --name nexus -e INSTALL4J_ADD_VM_PARAMS="-Xms2g -Xmx2g -XX:MaxDirectMemorySize=3g -Djava.util.prefs.userRoot=/some-other-dir" sonatype/nexus3# 持久化/nexus-data目录到docker volume$ docker volume create --name nexus-data$ docker run -d -p 8081:8081 --name nexus -v nexus-data:/nexus-data sonatype/nexus3# 持久化到主机的目录（不具便携性）$ mkdir /some/dir/nexus-data &amp;&amp; chown -R 200 /some/dir/nexus-data$ docker run -d -p 8081:8081 --name nexus -v /some/dir/nexus-data:/nexus-data sonatype/nexus3# 自己通过nexus3的image为基础Build一个新的image$ docker build --rm=true --tag=sonatype/nexus3 .#The following optional variables can be used when building the image:# NEXUS_VERSION: Version of the Nexus Repository Manager# NEXUS_DOWNLOAD_URL: Download URL for Nexus Repository, alternative to using NEXUS_VERSION to download from Sonatype# NEXUS_DOWNLOAD_SHA256_HASH: Sha256 checksum for the downloaded Nexus Repository Manager archive. Required if NEXUS_VERSION or NEXUS_DOWNLOAD_URL is provided 配置Yum RepositoryYum的Repository分为proxy和host两种，两种分别用于不同的用途： Host——如果是为了存放公司内部的rpm，那么创建Host类型的repository，设置定时任务更新metadata，以提供公司内部使用。一般须要做的配置的内容包括： Repository的名字 Repodata深度，用于指定从第几层目录开始创建metadata 指定Blob store，事先创建的blob store是repo库存放的目录 然后就可以上传rpm了，上传的方式其实就是对repo的链接做HTTP POST，这里用crul示例 1curl -v --user 'admin:admin123' --upload-file ./test.rpm http://localhost:8081/repository/yum-hosted/test.rpm 最后，使用Rebuild Yum metadata的schedule task来重建metadata Proxy——如果目的是让客户端直接使用外网的repository，可以使用这种类型作为代理，proxy里只会存放客户端下载过的rpm。这里着重介绍这种方式。 Proxy Repository创建的方法非常简单，完全图形化，主要须要配置的也就是须要代理的公网repository，比如: centos可以用http://mirror.centos.org/centos/ epel用http://mirrors.aliyun.com/epel/ 这里录了屏 完成后就可以配置客户端使用这个repo了（在刚才配置的repo里可以看到访问链接），下面是centos和epel的repo文件示例：12345678910111213141516171819202122232425262728293031[root@client01 yum.repos.d]# cat nexus.repo[nexus]name=Nexus Repositorybaseurl=http://repo.mylab.com:8081/repository/yum-proxy/$releasever/os/$basearch/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7priority=1[root@client01 yum.repos.d]# cat nexus-epel.repo[nexus-epel-debuginfo]name = Extra Packages for Enterprise Linux 7 - $basearch - Debugbaseurl = http://repo.mylab.com:8081/repository/yum-epel-proxy/7/$basearch/debugfailovermethod = priorityenabled = 0gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7gpgcheck = 0[nexus-epel-source]name = Extra Packages for Enterprise Linux 7 - $basearch - Sourcebaseurl = http://repo.mylab.com:8081/repository/yum-epel-proxy/7/SRPMSfailovermethod = priorityenabled = 0gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7gpgcheck = 0[nexus-epel]baseurl = http://repo.mylab.com:8081/repository/yum-epel-proxy/7/$basearchfailovermethod = prioritygpgcheck = 0name = EPEL YUM repo 至此，客户端就可以连接自己的repo服务器下载rpm了，如果所须要的包是第一次下载，那么proxy会连接指定的外网repo下载，但如果是proxy已经存在的repo，那么直接从proxy上拉下来，速度会比外网下载快很很多！ 1.Nexus Repository Manager 3.5: Yum Proxy Support Now Available ↩2.Nexus Repository Manager 3 ↩3.Sonatype Nexus3 Docker ↩]]></content>
      <categories>
        <category>学习</category>
        <category>Nexus</category>
      </categories>
      <tags>
        <tag>Nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Linux和Docker上使用PowerCLI]]></title>
    <url>%2F2018%2F03%2F30%2FLinuxPowerCLI%2F</url>
    <content type="text"><![CDATA[奚有米一岁啦！先来张庆生照！ 时间过的真快，VMware也已经10周年了，PowerCLI也在上个月发布了新的版本，版本号也直接从6.5到了10[1]，就是为了10周年的缘故吧，在slack的讨论里也有这样的解释： Because 7 8(ate) 9 随着这次的版本的更新，更是加入了对MacOS和多种Linux发行版本的支持，这个月其Docker版本也有了更新。所以这篇博客记录下几种不同环境下PowerCLI的安装方法。 Linux安装PowerCLI目前官方已经支持在MacOS和好几种Linux发行版上使用PowerCLI，这里测试的机器是CentOS7。 实际上，正是因为现在.net core和PowerShell已经支持了在多种操作系统上运行，所以使得PowerCLI作为一个PowerShell模块可以运行在Linux和MacOS。 安装步骤也比较简单： 安装PowerShell 12[root@host1 ~]# curl https://packages.microsoft.com/config/rhel/7/prod.repo | sudo tee /etc/yum.repos.d/microsoft.repo[root@host1 ~]# yum install powershell 安装PowerCLI模块 12345678[root@host1 ~]# pwshPowerShell v6.1.0-preview.1Copyright (c) Microsoft Corporation. All rights reserved.https://aka.ms/pscore6-docsType 'help' to get help.PS /root&gt; install-module vmware.powercli -Scope CurrentUser 安装完成的powercli module目录会在 ~/.local/share/powershell/Modules/接下来就可以直接使用PowerCLI命令了。 MacOS环境下的安装这里就省略了，具体步骤可以参考官方博客[2] 通过Docker使用PowerCLI我这里使用PhotonOS v2测试了Docker下使用PowerCLI，安装使用也非常简单： 下载PowerCLI Image 1234567891011121314151617root@PhotonOS2 [ ~ ]# docker pull vmware/powerclicoreUsing default tag: latestlatest: Pulling from vmware/powerclicoree9b1ffebdf09: Pull complete1ca0671214e4: Pull completee2054d0e7b6e: Downloading [=================&gt; ] 29.73MB/83.88MB9e5896375981: Download completee2054d0e7b6e: Downloading [===============================&gt; ] 52.98MB/83.88MBe2054d0e7b6e: Downloading [====================================&gt; ] 12.85MB/17.76MBe2054d0e7b6e: Pull complete9e5896375981: Pull complete4fda4ed0aa8e: Pull completeae595f021807: Pull complete2223c2963494: Pull completec0625c88535b: Pull completeDigest: sha256:4c19d7f6e5b460cdcea403977f1e8491f5c28c81a60e84dddf9d65921ba3ac51Status: Downloaded newer image for vmware/powerclicore:latest 运行PowerCLI container 1234567891011121314151617181920root@PhotonOS2 [ ~ ]# docker run -it vmware/powerclicorePowerShell v6.0.1Copyright (c) Microsoft Corporation. All rights reserved.https://aka.ms/pscore6-docsType 'help' to get help.PS /root&gt; $PSVersionTableName Value---- -----PSVersion 6.0.1PSEdition CoreGitCommitId v6.0.1OS Linux 4.9.80-1.ph2-esx #1-photon SMP Wed Feb 14 14:45:42 UTC 2018Platform UnixPSCompatibleVersions &#123;1.0, 2.0, 3.0, 4.0...&#125;PSRemotingProtocolVersion 2.3SerializationVersion 1.1.0.1WSManStackVersion 3.0 时间就是知识，时间就是力量，时间就是生命。——郭沫若 1.New Release: VMware PowerCLI 10.0.0 ↩2.Installing PowerCLI 10.0.0 on MacOS ↩]]></content>
      <categories>
        <category>学习</category>
        <category>VMware</category>
      </categories>
      <tags>
        <tag>PowerCLI</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ChatOps! 自制Poshbot插件管理VMware]]></title>
    <url>%2F2018%2F03%2F18%2FPoshBotVMware%2F</url>
    <content type="text"><![CDATA[这些词你有听说过嘛？ DevOps ChatOps AIOps NoOps OOooooopps…这里写的内容是ChatOps…就像过完年这段时间特别的忙，手机上几十个聊天群，这时候ChatOps这个词浮现再眼前~本质上讲，ChatOps其实意思就是聊天群里来了个机器人，这家伙会截取特定聊天内容，执行对应的动作，比方说吧： ”看看Ben的账号是不是锁了“ ”虚拟机vm1创建个快照，让Jacky审批下“ “每天早上9点发个数据库报表” ”开个P2的ticket” 上面这些，对于聊天群里的机器人bot就是指令command，至于我们人类嘛，就发号施令就行啦！（当然，实际上也就是摆脱了这些琐事，从而把更多精力放在开发这些指令上） 这里我写了个Poshbot的插件，插件的功能是管理VMware，算是一个ChatOps的实践。插件的演示视频如下： PoshBot这应该不算是一个主流的ChatOps软件，我也是之前在研究DSC的时候碰巧看到的，无论如何，对我等凡人而言，这也是大神作品了，这里贡上Github的链接[1]。 这个项目使用的是PowerShell，所以使用这个项目来实现ChatOps对我而言，很好的提供了管理VMware的办法，相应的插件直接写PowerCLI就行。 PoshBot的安装使用方法可以直接参考项目的README，里面包含了文档网站和大神的介绍视频，另外这里还有另外一个参与contribute的大神的Blog[2]，我上面的视频里面没有介绍PoshBot的安装使用方法，在这里就简要列一下： 首先在Slack上创建一个workspace，并在这个workspace上创建一个bot，记录下token和机器人的名字，另外还得至少有个人做bot的管理员，记录下这个slack用户名。 Install-Module安装PoshBot，如果报错说Module里须要export的function已经使用，安装时加上-AllowClobber参数。 创建一份对应刚才这个bot的配置文件，并以这份配置文件为参数启动Poshbot。 12$backendConfig = @&#123;Name = 'SlackBackend'; Token = '&lt;SLACK-API-TOKEN&gt;'; BotAdmins = @('&lt;SLACK-CHAT-HANDLE&gt;')&#125;$backend = New-PoshBotSlackBackend -Configuration $backendConfig 接下来就可以在slack里使用了 首先把bot邀请到须要使用的channel里 然后管理员用户直接输入poshbot命令!About查看bot状态，这种感叹号作为前置的命令，就是Poshbot命令 其他的内置bot命令可以使用!help查看 好了，至此bot已经上线并可以正常和人交互了。 Plugin安装并启动了Poshbot后，只是加载了内置的功能，而我们真正想使用bot来实现ChatOps，就需要编写对应的Plugin。插件其实就是Powershell的Module，所以其实调用起来非常方便，简单讲就下面3步： 编写Module，并且推荐使用命名为Poshbot.ModuleName 把Module放在Poshbot配置文件指定的Plugin目录，或者就是Powershell的模块目录，所以，plugin的模块是可以和其他module一样放在powershell gallery上。甚至内置的命令的find-plugin/install-plugin都是可以直接连接powershell gallery来获取插件模块的 如果是手动复制或者Install-Module的方式安装的插件模块，那么还需要再在slack里使用!install-plugin来安装一次，使得poshbot更新相应的plugin配置文件。 至此plugin就安装完成并可以使用了，同样，也是用!help等命令了解这个plugin。 作为实践测试，我自己编写了个管理VMware的plugin[3]，大致思路如下： 首先，bot得放在一个同时可以访问slack网站和访问的VIServer(vcenter/esxi)的机器上 然后plugin须要存储VIServer及其对应的credential的办法，这样每次执行命令时都能自动连接这些VIServer，这个用了这些方法实现： VIServer的存储通过poshbot配置文件设置一个自定义的目录 目录里存放以VIServer名和登陆用名组成的xml文件 文件内存放加密后的登陆密码 目录下一层创建DisabledVIServer目录，不需要连接的服务器可以暂时disable 所有对VI Server增删改和加密解密都使用私有函数，这样确保没法通过bot command调用，只有配置bot服务器的人才能通过脚本调用 最终，通过脚本调用私有函数实现 New/Remove/Enable/Disable VI Server 最后plugin自身功能就是调用poshbot的plugin配置的VIServer目录，连接服务器来实现相应的功能command 具体实现须要用到几个poshbot相关的技术： plugin配置[4]——由于VIServer列表的存放路径写在poshbot配置中，通过在模块函数中添加如下PoshBot.FromConfig这个attribute 123456[cmdletbinding()]param( [PoshBot.FromConfig('VIServerConfigStore')] [parameter(Mandatory = $true)] [string]$VIServerConfigStore,) 作为powershell module，作为command的函数除了自身的函数命名，还使用了下面这种attribute命名Poshbot command 1[PoshBot.BotCommand(CommandName = 'getsnapshot', Permissions = 'snapshot')] 最后，必须留意的是PoshBot最好不要直接拿对象Write-Output，尽可能转换成String输出，这里用到PoshBot的New-PoshBotCardResponse 123$r| ForEach-Object &#123; New-PoshBotCardResponse -Title "VM $($_.vm) snapshot:" -Text ($_ | Format-List -Property vm, name | Out-String)&#125; 另外，这里关于如何创建bot和加密VIServer的密码就不再赘述了，具体可以参考slack的网站和查看我的代码。 其他建议使用的功能Poshbot其实还提供了很多其他的功能，比如 基于角色的访问控制RBAC 计划任务 基于聊天室事件触发的命令 Bot允许的Channel 审批 比如像我开发的这个VMware插件，像createsnapshot就可以尝试使用审批功能。 总之估计这个项目的作者肯定还会不断开发新的功能，有兴趣可以查看文档尝试使用并自行开发插件。期待更多伙伴们参与ChatOps！ 1.PoshBot Github ↩2.Getting Started with PoshBot ↩3.Poshbot.VMware ↩4.PoshBot Plugin Configuration ↩]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
        <tag>Slack</tag>
        <tag>ChatOps</tag>
        <tag>VMware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用DSCEA和BaselineManagement做合规检查]]></title>
    <url>%2F2018%2F02%2F27%2FWinBaseline%2F</url>
    <content type="text"><![CDATA[这里所说的合规检查指的是Windows Baseline Compliance Check。 原本微软有个SCM的安全检查工具[1]，可以做合规检查的工作，但是目前这个工具已经退役了，并因此推荐了这篇博客所提及的两个开源工具DSCEA和BaselineManagement[2]，另外还有SCT这个工具[3]，总之，关于安全合规，可以参考微软官方文档[4]了解更多。 当然，合规也未必只限于安全方面，说到底，只要系统和自己定义的配置相符，那么就可以认为是合规。 这里用“有米饺”举个例子，嘿嘿(●ˇ∀ˇ●) 所以，DSCEA内部使用Test-DscConfiguration，很好的做到了检查相应的配置，而不局限于安全方面。 由于BaselineManagement和DSCEA作为开源的PowerShell程序，目前官方的文档还比较少，很多还是依赖于社区资源，所以这里记录下使用方法。 BaselineManagement这个项目的官方README介绍[5]模块作用是把SCM的XML/JSON或者GPO直接转换成DSC的MOF文件，省下了自己手动写DSC配置脚本的大量工作。目前我只使用了转换GPO的功能，大致步骤如下： 准备好GPO文件/目录——通常，要看所需GPO的具体设置，GPO可能会包含几种文件，可以通过GPM或LGPO这类工具备份/导出。 在执行转换的机器上安装BaselineManagement模块，包括如下： 首先，当然是至少须要是PowerShell 5。 Install-Module BaselineManagement安装模块，测试下来必须安装在AllUsers的Scope下，否则模块执行会报错。 可选的，安装如下模块： Carbon, xSmbShare, DSCR_PowerPlan, xScheduledTask，这几个模块可以通过PSGallery直接安装。 rsInternationalSettings, PrinterManagement，这两个模块没有上传到PSGallery只能通过github下载手动复制到$env:PSModulePath目录。 执行转换命令ConvertFrom-GPO -Path PathToGPO，生成mof文件。 DSCEA有了上面BaselineManagement生成的DSC .mof文件，接下来就可以使用DSCEA来扫描机器是否符合相应的DSC配置。实际上对于DSCEA而言，其本身从哪里拿的DSC配置文件并不重要，所以这里也就不限定于刚才的SCM或GPO这些与安全合规关系比较大的配置了。DSCEA他起的作用只是扫描机器并产生报表。DSCEA有比较完善的文档[6]，其中有几个自己生成DSC配置的Sample，这里就不再详细写使用方法了，下面直接把结合两个工具的整个使用过程录制了下来。 1.Security Compliance Manager ↩2.Security Compliance Manager retired; new tools and procedures ↩3.Microsoft Security Compliance Toolkit 1.0 ↩4.Windows Security Baselines ↩5.BaselineManagement README ↩6.DSCEA文档 ↩]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
        <tag>DSC</tag>
        <tag>Group Policy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DSC使用https的winrm]]></title>
    <url>%2F2018%2F02%2F18%2FDSCwinrm%2F</url>
    <content type="text"><![CDATA[时至二零一八农历戊戌（狗）年春节，奚有米先来拜个年啦！ 新年长假后会有一个拖延了很久的任务须要完成，于是着手研究怎么使用DSC，其中包含了winrm的配置，这篇博客简单记录下相关经验： 初始winrm。[1] 使用winrm的https方法。[2] https是否会过期。[3] 通过GPO分发winrm证书的方法。[4] winrm默认配置(http 5985)目前winrm在windows2012r2之后版本默认开启了http listener 5985端口，可以通过下面命令测试winrm连接，须要注意： 默认winrm服务端basic认证为false，也就是至少须要AD或证书等方式认证。 须要使用FQDN连接。 通常防火墙默认已经开启5985端口。 1234567891011121314151617PS C:\Users\xiyoumi&gt; Enter-PSSession -ComputerName server001.lab.com[server001.lab.com]: PS C:\Users\xiyoumi\Documents&gt; winrm e winrm/config/listenerListener Address = * Transport = HTTP Port = 5985 Hostname Enabled = true URLPrefix = wsman CertificateThumbprint ListeningOn = 192.168.32.12, 127.0.0.1, ::1, fe80::5efe:10.196.32.74%15, fe80::8de8:50db:9107:696a%13[server001.lab.com]: PS C:\Users\xiyoumi\Documents&gt; hostnameserver001[server001.lab.com]: PS C:\Users\xiyoumi\Documents&gt; (Get-WmiObject -class Win32_OperatingSystem).CaptionMicrosoft Windows Server 2012 R2 Standard 上面例子连接到server001.lab.com，并使用winrm命令查看listener配置。由于这是一台windows 2012 R2的服务器，所以winrm已经默认开启。下面命令从头开启一台服务器的winrm默认配置： 12345678910111213141516171819202122232425262728PS C:\Users\xiyoumi&gt; winrm e winrm/config/listenerPS C:\Users\xiyoumi&gt; Enable-PSRemotingWinRM Quick ConfigurationRunning command "Set-WSManQuickConfig" to enable remote management of this computer by using the Windows RemoteManagement (WinRM) service. This includes: 1. Starting or restarting (if already started) the WinRM service 2. Setting the WinRM service startup type to Automatic 3. Creating a listener to accept requests on any IP address 4. Enabling Windows Firewall inbound rule exceptions for WS-Management traffic (for http only).Do you want to continue?[Y] Yes [A] Yes to All [N] No [L] No to All [S] Suspend [?] Help (default is "Y"):WinRM is already set up to receive requests on this computer.WinRM has been updated for remote management.Created a WinRM listener on HTTP://* to accept WS-Man requests to any IP on this machine.PS C:\Users\xiyoumi&gt; winrm e winrm/config/listenerListener Address = * Transport = HTTP Port = 5985 Hostname Enabled = true URLPrefix = wsman CertificateThumbprint ListeningOn = 10.196.32.110, 127.0.0.1, ::1, fe80::100:7f:fffe%13 总的来说比较简单，一条命令解决，如果是没有加入域的机器，可以通过加-SkipNetworkProfileCheck参数，开启public zone的防火墙。当然也可以不用这个cmdlet，直接使用winrm命令：12345678910111213141516171819202122232425C:\&gt; winrm quickconfigWinRM is not set up to receive requests on this machine.The following changes must be made: Set the WinRM service type to delayed auto start. Make these changes [y/n]? y WinRM has been updated to receive requests. WinRM service type changed successfully.WinRM is not set up to allow remote access to this machine for management.The following changes must be made: Create a WinRM listener on HTTP://* to accept WS-Man requests to any IP on this machine.Enable the WinRM firewall exception.Configure LocalAccountTokenFilterPolicy to grant administrative rights remotely to local users. Make these changes [y/n]? y WinRM has been updated for remote management. Created a WinRM listener on HTTP://* to accept WS-Man requests to any IP on this machine.WinRM firewall exception enabled.Configured LocalAccountTokenFilterPolicy to grant administrative rights remotely to local users. 另外，关闭winrm可以使用下面步骤： 删除Listener 1winrm delete winrm/config/Listener?Address=*+Transport=HTTP 配置并停止winrm服务 12Set-Service -Name winrm -StartupType DisabledStop-Service winrm 开启防火墙 1Get-NetFirewallRule | ? &#123;$_.Displayname -eq "Windows Remote Management (HTTP-In)"&#125; | Set-NetFirewallRule -Enabled "False" 上述就是一般情况的winrm使用方法，下面继续配置https的方法 winrm配置https首先，可以先通过默认的winrm配置测试连接已经没有问题。和http相似，https方式大致也包括下面几个配置： WinRM服务正常运行 防火墙配置（须要手动添加5986端口） 添加https的Listener（须要事先生成winrm证书） 在具体开始配置之前，这里推荐一下Ansible使用的winrm配置脚本，可以直接github下载，或者从ansible的windows文档提供的链接下载examples/scripts/ConfigureRemotingForAnsible.ps1 这个脚本直接可以生成自签名证书，然后开启服务和防火墙，并完成listener配置。如果实在想要自己完成这些操作的话，通过下面这些命令实现： 开启并配置winrm服务 12Set-Service -Name winrm -StartupType AutomaticStart-Service winrm 创建自签名证书。 1New-SelfSignedCertificate -DnsName "&lt;YOUR_DNS_NAME&gt;" -CertStoreLocation Cert:\LocalMachine\My 创建https winrm listener，这里的thumbprint就是刚才生成证书的thumbprint 123456789101112131415161718PS C:\Users\xiyoumi&gt; Get-ChildItem -path cert:\LocalMachine\My PSParentPath: Microsoft.PowerShell.Security\Certificate::LocalMachine\MyThumbprint Subject---------- -------15EC9566CF4E5F3563BFE3161676E16BAAB52DD3 CN=HP840G1PS C:\Users\xiyoumi&gt; $selectorset = @&#123; Address = "*" Transport = "HTTPS"&#125;PS C:\Users\xiyoumi&gt; $valueset = @&#123;CertificateThumbprint = "15ec9566cf4e5f3563bfe3161676e16baab52dd3"Hostname = "HP840G1"&#125;PS C:\Users\xiyoumi&gt; New-WSManInstance -ResourceURI 'winrm/config/Listener' -SelectorSet $selectorset -ValueSet $valueset 添加防火墙规则，允许5986端口访问 12PS C:\Users\xiyoumi&gt; $port=5986PS C:\Users\xiyoumi&gt; netsh advfirewall firewall add rule name="Windows Remote Management (HTTPS-In)" dir=in action=allow protocol=TCP localport=$port 完成上面几部后，https的winrm就已经完成配置了，可选的我们可以删除原有的http listener： 1winrm delete winrm/config/Listener?Address=*+Transport=HTTP 须要测试https连接可以使用下面命令： 1Enter-PSSession -ComputerName HP840G1 -Port 5986 -SessionOption (New-PSSessionOption -SkipCACheck) -UseSSL 狗年旺起来！(੭ˊᵕˋ)੭*ଘ 1.Installation and Configuration for Windows Remote Management ↩2.How to configure WinRM for HTTPS manually ↩3.WinRM and HTTPs – What happens when certs expired ↩4.WinRM SSL Certificate Deployment via GPO ↩]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
        <tag>DSC</tag>
        <tag>winrm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PowerShell 学习笔记]]></title>
    <url>%2F2018%2F02%2F02%2FPowerShell_Study%2F</url>
    <content type="text"><![CDATA[这一篇主要目的其实是为炫耀下奚有米的工作环境(￣y▽,￣)╭其次才是总结一下这段时间写PowerShell的心得。 所以，先上奚有米工作图。 Look！ 豪华6屏联动！同时掌控5个操作系统（加上虚拟机7种操作系统）！老夫一把键盘游刃有余！ 竖着的代码屏——VS Code的ZenMode。 Apple Air——Google/GitHub/stackoverflow 复制！黏贴！ HP Elite——收收邮件开开会~填填表格写写文档，这就是为啥公司派的电脑配置再好也总是让人讨厌的原因~。 Dell XPS——可选，Ubuntu里Dock跑测试，当然实际上可以直接跑在工作机、虚拟机或云上面。 iPad——Slack上聊个天而已。 华为P9——还是微信最贴合国人需求。 PowerShell DSC目前工作环境还没有真的使用，这里留个沙发位给他。目前参考文档有： DCS官网文档——必不可少。 DSC使用Pester和AppVeyor做测试——Warren F大神关于DCS测试的博客，编写复杂配置的时候，不妨使用这个方法测试。 vSphereDCS系列——LucD大神嫁接vSphere的DCS实现，其中创意的把LCM放在一个独立的可以连接vcenter的服务器上（当然可以是vcenter本身），可惜目前项目进度感觉有点停滞了~ Vester这个开源项目着实解决了我的一些实际工作需求。Vester借助Pester实现对vSphere环境的检查(Test)，并且可以做相应的修复(Remediate)。当然检查和修复的脚本项目自身已经提供了不少，我在实际工作中也写了些，放在自己的fork里。主要补充了： 一些Host的Tests 支持配置使用HashTable Compare-HashTablePowerShell自带的Compare-Object不能有效的比较HashTable，这里改写了网上某神的函数，实现递归的比较带嵌套的HashTable，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061function Compare-Hashtable &#123;&lt;#.SYNOPSISCompare two Hashtable and returns an array of differences..DESCRIPTIONThe Compare-Hashtable function computes differences between two Hashtables. Results are returned asan array of objects with the properties: "key" (the name of the key that caused a difference), "side" (one of "&lt;=", "!=" or "=&gt;"), "lvalue" an "rvalue" (resp. the left and right value associated with the key)..PARAMETER left The left hand side Hashtable to compare..PARAMETER right The right hand side Hashtable to compare..EXAMPLEReturns a difference for ("3 &lt;="), c (3 "!=" 4) and e ("=&gt;" 5).Compare-Hashtable @&#123; a = 1; b = 2; c = 3 &#125; @&#123; b = 2; c = 4; e = 5&#125;.EXAMPLE Returns a difference for a ("3 &lt;="), c (3 "!=" 4), e ("=&gt;" 5) and g (6 "&lt;=").$left = @&#123; a = 1; b = 2; c = 3; f = $Null; g = 6 &#125;$right = @&#123; b = 2; c = 4; e = 5; f = $Null; g = $Null &#125;Compare-Hashtable $left $right#&gt; [CmdletBinding()] param ( [Parameter(Mandatory = $true)] [Hashtable]$Left, [Parameter(Mandatory = $true)] [Hashtable]$Right ) function New-Result($Key, $LValue, $Side, $RValue) &#123; New-Object -Type PSObject -Property @&#123; key = $Key lvalue = $LValue rvalue = $RValue side = $Side &#125; &#125; [Object[]]$Results = $Left.Keys | % &#123; if ($Left.ContainsKey($_) -and !$Right.ContainsKey($_)) &#123; New-Result $_ $Left[$_] "&lt;=" $Null &#125; else &#123; if ($Left[$_] -is [hashtable] -and $Right[$_] -is [hashtable] ) &#123; Compare-Hashtable $Left[$_] $Right[$_] &#125; else &#123; $LValue, $RValue = $Left[$_], $Right[$_] if ($LValue -ne $RValue) &#123; New-Result $_ $LValue "!=" $RValue &#125; &#125; &#125; &#125; $Results += $Right.Keys | % &#123; if (!$Left.ContainsKey($_) -and $Right.ContainsKey($_)) &#123; New-Result $_ $Null "=&gt;" $Right[$_] &#125; &#125; if ($Results -ne $null) &#123; $Results &#125;&#125; PSObject和HashTable互转有个现成的MSDN博客提供了两个互转的函数。实际使用时stackoverflow里提供了两种方法也不错。首先时直接循环对象的属性：1234567# Create a PSCustomObject (ironically using a hashtable)$ht1 = @&#123; A = 'a'; B = 'b'; DateTime = Get-Date &#125;$theObject = new-object psobject -Property $ht1# Convert the PSCustomObject back to a hashtable$ht2 = @&#123;&#125;$theObject.psobject.properties | Foreach &#123; $ht2[$_.Name] = $_.Value &#125; 还有就是如果须要转换嵌套对象，就使用这个函数：12345678910111213141516171819function ConvertPSObjectToHashtable &#123; param ( [Parameter(ValueFromPipeline)] $InputObject ) process &#123; if ($InputObject -is [psobject])&#123; $hash = @&#123;&#125; foreach ($property in $InputObject.PSObject.Properties)&#123; $hash[$property.Name] = ConvertPSObjectToHashtable $property.Value &#125; $hash &#125; else&#123; $InputObject &#125; &#125; &#125; 参数选项这里墙裂推荐PowerShell中文博客，标签云里提供了很多种参数用法。当然，参考官方文档总能有全面详细的参数使用帮助。 最后，农历狗年即将到来，预祝一下今年会旺(੭ˊᵕˋ)੭*ଘ]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PowerShell 一把梭]]></title>
    <url>%2F2018%2F01%2F15%2FPowerShellPipeline%2F</url>
    <content type="text"><![CDATA[本来标题想叫《PowerShell实现模块发布流水线》的，但是这个洋气高大上的标题抄袭痕迹太严重了，好吧，不得不承认我的学习成果通常都是大量参(copy)考(paste)大神博客的。（估计写个爬虫爬一下我的博客，也会发现大神这个词出现频率肥肠高~） 先用下面这个视频解释下什么是流水线~嘿嘿，玩笑啦~(￣▽￣)~* 其实还是从字面解释吧，PowerShell模块–发布–流水线： PowerShell模块——把脚本写成模块。 发布——把写好的模块发布给其他人用，比如上传到PowerShell Gallery。一般来说发布前要做好打包和测试。 流水线——写好代码提交版本后，自动完成打包–测试–发布这些动作，比如提交到GitHub后AppVeyor完成自动化流水线操作。 在开始之前可能先找个例子作解释更好，所以这里把我已经提交GitHub并发布在PSGallery的一个名字叫BaselineCheck的模块作为例子。良好的目录结构(Scaffold)是程序员自我修养的一部分，我这里大致是这个样子：123456789101112131415161718192021222324252627282930313233343536D:\DOC\GITHUB\BASELINECHECK│ .gitignore│ appveyor.yml————AppVeyor配置文件│ BaselineCheck.psd1————模块的manifest│ BaselineCheck.psm1————模块本身│ Build.ps1————VScode提供的psake脚本│ LICENSE│ README.md│├───.vscode│ launch.json————VScode调试配置│ tasks.json————VScode任务配置│├───Build————使用AppVeyor相关的一大堆脚本│ │ build.requirements.psd1│ │ deploy.psdeploy.ps1│ │ psake.ps1│ │ Start-Build.ps1│ ││ └───helpers│ Install-PSDepend.ps1│├───Images│ PowerShell_icon.png│├───Private————私有函数，不export给用户使用│ Get-FileName.ps1│├───Public————公有函数，会export出来│ Compare-Rsop.ps1│ Compare-ScriptOutput.ps1│ Find-RsopSetting.ps1│ Find-XmlNodes.ps1│└───Tests————Pester测试脚本 BaselineCheck.Tests.ps1 这个目录结构的好处是： 每次新建项目可以直接拷贝使用，基本上只要修改功能代码和测试脚本就行。 包含了VScode的手动触发的任务和AppVeyor自动流水线的脚本。 PowerShell 模块写成模块又很多好处，比如下面这一把梭： Simplify code organization Group related functions together Share state between functions, but not with the user Re-use “helper functions” that you don’t want exposed to the user Improve discoverability: Find-Module MyModule or Get-Command -Module MyModule Simplify distribution: Install-Module MyModule 具体做起来，当然看下写模块的官方文档是很值得的，自己总结下来也就3步： 写完功能代码.ps1——可选项：建议写成函数方式，可能的话函数可以使用begin-process-end方式处理管道。 写一个模块代码.psm1——可以直接把.ps1改名成.psm1，但是通常代码会包含多个.ps1，所以把代码按照scaffold组织存放.ps1，然后写一个.psm1来调用，所以这个模块调用代码也是一劳永逸，不用修改。 生成Manifest文件.psd1——可以直接拷贝官网例子（自己用New-Guid改个GUID），也可以用New-ModuleManifest命令生成，然后修改下里面的版本和导出函数等等的设置。 这样模块最基本所需要的内容就算完成了，如果还要写帮助文档、Format.ps1xml，建议继续参考大神博客吧~ 打包-测试-发布前面说了整个流水线的包含了打包-测试-发布这些步骤，这里逐一列出所需要使用的工具。其中psake/BuildHelpers/PSDepend/PSDeploy这些模块须要从PSGallery下载安装，以安装psake举例，命令如下：1Install-Module psake -scope currentuser -force psakepsake这个powershell模块用来自动化整个流程，用它提供的函数可以把各个步骤写成下面这个互相有依赖关系的任务模块：12345678910111213141516171819202122232425Properties &#123; $someproperty = 'Define some properties for following tasks'&#125;Task default -depends BuildTask Init &#123; 'Write init code'&#125;Task Clean &#123; 'Write some clean code'&#125;Task Build -depends Clean, Init -requiredVariables someproperty &#123; 'Write some build code'&#125;Task Test -depends Build &#123; 'Write some test code, for example, invoke-pester...'&#125;Task Publish -depends Test &#123; 'Write some publish code, for example, Invoke-PSDeploy'&#125; VScode的task和AppVeyor都是通过调用psake来完成流程相应步骤的，接下来是完成各个发布步骤的工具了。 打包Build打包在这里没有用到什么特殊的工具，我在脚本里就做下面两件事情： 更新下Model Manifest 把模块相关的文件复制到Release目录 具体代码不再黏贴，可以直接参考Build.ps1和Build\psake.ps1两个文件。 pesterpester是powershell的测试模块，现在已经集成到win10和win2016里，所以除非想要升级PSGallery上的最新版，一般也就不需要安装了。我们可以自己写测试脚本，写完后可以放在比如Tests目录，用Invoke-Pester来调用测试。每个项目的测试内容也不会相同，这里举个测试模块.psd1文件的例子：12345678910111213141516$Verbose = @&#123;&#125;if($env:APPVEYOR_REPO_BRANCH -and $env:APPVEYOR_REPO_BRANCH -notlike "master")&#123; $Verbose.add("Verbose",$True)&#125;$PSVersion = $PSVersionTable.PSVersion.Major$ModuleManifestName = 'BaselineCheck.psd1'Import-Module $PSScriptRoot\..\$ModuleManifestNameDescribe 'Module Manifest Tests' &#123; It 'Passes Test-ModuleManifest' &#123; Test-ModuleManifest -Path $PSScriptRoot\..\$ModuleManifestName $? | Should Be $true &#125;&#125; 可见测试其本身也是一个powershell脚本，只是其中调用了pester提供的函数Describe/It/Should Be等等。Pester的具体的语法可以参考官方Wiki。 发布，PSdeploy发布要看具体是要发布到哪里了，比如说： 发布到PowerShell Gallery 在github上生成个release AppVeyor上生成个Artifacts 把模块目录直接复制到$PSModulePath来安装，也算是发布 总之，发布就是把做好的模块放出来，这样就可以给别人用了。我这里主要就是发布到PowerShell Gallery。用到的模块是PSdeploy。 PSDeploy通过Invoke-PSDeploy来调用Build目录，其中包含deploy.psdeploy.ps1文件，下面是部署到PSGallery的代码：123456789Deploy Module &#123; By PSGalleryModule &#123; FromSource $ENV:PublishDir To PSGallery WithOptions @&#123; ApiKey = $ENV:NugetApiKey &#125; &#125;&#125; 其用法看似和psake和Pester那些Alias语法很像，其中$ENV:NugetApiKey是PSGallery的API key，通过这个key来验证上传模块。PSDeploy可以做很多种类型的发布，具体用法也可以参考官方的readthedocs。 流水线流水线就是把上面打包-测试-发布这些动作组合在一起使用，所以，可见上面这些模块里psake的重要性。然后，就是要选好调用psake的方法了，在示例的repo里，我用了VScode和AppVeyor两种方式： VS Code —— 适合于本地项目，通过task完成打包、测试、发布等操作。 AppVeyor —— 集成GitHub或其他VSC的CI工具，直接提交代码触发相应条件来完成各个CI操作。 VS Code Task在VSCode里按下F1然后输入example可以查看VS Code的示例代码，其中就有如何设置Task的方法。除了前面说到的psake，大致再复制黏贴下example的两个文件就行： .vscode\tasks.json——用来设置F1后输入task可调用的任务。 Build.ps1——是psake脚本，VSCode通过调用这个脚本来执行对应的任务。 这里可能须要自己手动修改这个psake脚本，比如修改不需要打包的目录和文件，是否须要使用releasenotes文件等等。脚本发布默认也是发布到PSGallery（怎么注册PSGallery并获取API key这里不赘述了，反正网站上点点就行），第一次发布的时候会提示输入API key，这个key会加密保存到xml文件里，以后就不必要再输入了。（可以自行调用脚本里RemoveKey任务来删除Key，其实也就是手动删xml文件） AppVeyor作为一个公网服务，先去AppVeyor注册并关联自己的GitHub Repo，接下来就是写AppVeyor配置文件和相关的Build代码。这里我也是一把梭了大神的代码（整个Build目录和appveyor.yml文件），然后按自己情况改了发布目录而已。其中各个文件的作用如下： appveyor.yml——这个是必须的，我因为要发布到PSGallery，所以在AppVeyor上把PSGallery的API Key加密一下，放在yml文件里。 Start-Build.ps1——调用PSDepend检查所需要的模块，然后交给psake去处理流程各个步骤。 Install-PSDepend.ps1——如果PSDepend本身不存在，通过这个脚本来安装。 build.requirements.psd1——PSDepend列出的所需模块。 psake.ps1——具体流程的各个任务。这里可以包含一大堆任务，前面介绍了，具体不再赘述了。 deploy.psdeploy.ps1——通过psake发布任务调用，执行所需发布的类型。 总之，只要一提交GitHub，接下来会完成上面这一大堆任务了！ 还能做些什么？至此流水线完成，而且这样发布出来的代码结构也看上去很专业啦，哈哈。那么怎么再提升一点B格呢？我这里大致就是： 写好README 放个LICENSE RELEASE和RELEASE NOTES 此外大神们厉害的项目还会有issue和wiki~ 当然，关于流水线，还有很多须要学的地方，接下来自己也想学习怎么搭建Jenkins，好吧，少年~再接再厉~ o(￣▽￣)o]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
        <tag>Release Pipeline</tag>
        <tag>CD/CI</tag>
        <tag>VS Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PowerCLI IDE环境]]></title>
    <url>%2F2018%2F01%2F01%2Fpowershell_IDE%2F</url>
    <content type="text"><![CDATA[Happy New Year 2018 !!!奚有米先来送波祝福。 新的一年要继续好好学习，天天向上，在DevOps方面不断进步！ 工欲善其事，必先利其器 孔子（春秋）《论语·卫灵公》 为继续PowerShell方面的工作，这里整理起两个自己感觉非常好用的编辑器，并附上一些配置： PowerShell ISE + ISESteroids VS Code + PowerShell Extension 此外，由于经常须要写VMware PowerCLI，所以这里也附上了两个编辑器加载Module的方法。 PowerShell ISE + ISESteroids大致来讲相信多数写PowerShell都是从PowerShell ISE开始的，作为系统自带的PowerShell编辑器干净又好用（据说微软现在正在开发新的系统自带编辑器）。装上ISESteroids后，就完全是一个专业的IDE了，安装和配置也比较简单。安装方法可以直接参考ISESteroids官网的在线和离线安装步骤。这里提供两个配置的地方： 启动ISE后自动加载ISESteroids——如果启动的时候按住Ctrl键，则不会自动加载。 加载PowerCLI 6.5——启动的时候按住Alt键，才会自动加载。 两个配置我都是使用PowerShell ISE Profile，配置如下：123456789101112Add-Type -AssemblyName PresentationCoreif ([System.Windows.Input.Keyboard]::IsKeyDown('Ctrl') -eq $false)&#123; Start-Steroids&#125;if ([System.Windows.Input.Keyboard]::IsKeyDown('Alt') -eq $true)&#123; if (Get-Module -ListAvailable|Where-Object&#123;$_.name -eq "VMware.VimAutomation.Core"&#125;) &#123; Get-Module -ListAvailable VMware* | Import-Module &#125;&#125; VS Code + PowerShell Extension还记得刚学编程那会儿，Visual Studio 6.0那一大堆的CD，真是壮观~如今这个轻量却又功能强大的VS Code，用上手后非常喜欢！VS Code安装PowerShell Extension非常简单，直接在Extension里搜索PowerShell安装即可。配置上我参考了大神VSC for PowerCLI的博客。实现如下配置功能： 加载PowerCLI 6.5——启动的时候按住Alt键，才会自动加载。 Snippets——这里须要注意符号转义，比如下面的配置文件里使用\符号把PowerShell变量的$符号转义，但由于\符号本身再JSON里仍须要转义，所以最终powershell.json配置如下： 123456789101112131415&#123; "GestStat": &#123; "prefix": "PCLIStatVM", "body": [ "\\$finish = (Get-Date)", "\\$start = \\$finish.AddDays(-1)", "\\$stat = 'cpu.usage.average'", "\\$entities = Get-VM", "", "\\$stats = Get-Stat -Entity \\$entities -Stat \\$stat -Start \\$start -Finish \\$finish", "# \\$stats | Group-Object -Property EntityId" ], "description": "Sample VM statistics report" &#125;&#125; PowerShell Editor Services——自定义F1的PowerShell additional command。 配置实现使用VS Code PowerShell profile，确保VS Code的Preference-Setting (settings.json)里powershell.enableProfileLoading为默认的true。然后创建Microsoft.VSCode_profile.ps1或profile.ps1添加配置。我直接复制了大神的配置，由于不使用脚本里那么多种类的PowerCLI版本，直接修改成加载PowerCLI6.5模块。（原脚本是发现PowerCLI在注册表里的键值来确定版本，然而6.5已经不使用该键值，甚至新版本已经直接放在PowerShell Garllery上，所以不能再用原脚本的方式加载了） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Add-Type -AssemblyName PresentationCoreif ([System.Windows.Input.Keyboard]::IsKeyDown('Alt') -eq $true)&#123; if (Get-Module -ListAvailable|Where-Object&#123;$_.name -eq "VMware.VimAutomation.Core"&#125;) &#123; Get-Module -ListAvailable VMware* | Import-Module &#125;&#125;$pclihelp = &#123;$browser = 'chrome.exe'$pclisites = 'https://communities.vmware.com/community/vmtn/automationtools/powercli/content?filterID=contentstatus[published]~objecttype~objecttype[thread]','https://code.vmware.com/doc/preview?id=5975','https://code.vmware.com/apis/196/vsphere','http://blogs.vmware.com/PowerCLI','http://lucd.info'Start-Process $browser $pclisites&#125;Register-EditorCommand `-SuppressOutput `-Name 'PowerCLI.HelpSites' `-DisplayName 'PowerCLI Help Sites' `-ScriptBlock $pclihelp$pclicmdhelp = &#123;param([Parameter(Mandatory=$true)][Microsoft.PowerShell.EditorServices.Extensions.EditorContext]$context)$cmdlet = $context.CurrentFile.GetText($context.SelectedRange)$browser = 'chrome.exe'$cmdhelp = "https://code.vmware.com/doc/preview?id=5975#/doc/$($cmdlet).html" Start-Process $browser $cmdhelp &#125;Register-EditorCommand `-SuppressOutput `-Name 'PowerCLI.HelpCmdlet' `-DisplayName 'PowerCLI Cmdlet Help' `-ScriptBlock $pclicmdhelp$pscountcmdlet = &#123; param([Parameter(Mandatory=$true)][Microsoft.PowerShell.EditorServices.Extensions.EditorContext]$context) $cmdArr = @() $varArr = @() foreach($token in $context.CurrentFile.Tokens)&#123; switch($token.GetType().Name)&#123; 'StringLiteralToken'&#123; if($token.TokenFlags -eq 'CommandName')&#123; $cmdArr += $token.Value &#125; &#125; 'VariableToken'&#123; $varArr += $token.Name &#125; &#125; &#125; $cmdArr = $cmdArr | Sort-Object -Unique $varArr = $varArr | Sort-Object -Unique Write-Output "You used $($cmdArr.Count) different cmdlets" Write-Output "`t$($cmdArr -join '|')" Write-Output "You used $($varArr.Count) different variables" Write-Output "`t$($varArr -join '|')"&#125;Register-EditorCommand `-Name 'PowerShell.CountCmdletVar' `-DisplayName 'Count Cmdlets/Variables' `-ScriptBlock $pscountcmdlet 另外，VS Code实在很多可玩的地方，可以直接用在MACOS上提升逼格，可以直接Git（也可以用VSTS extension，须要visual studio的TS.exe），好多extension~ 比如映射VIM等其他编辑器的键盘设置，md语法检查，好多好多~好吧，Happy Coding 2018 &lt;(￣︶￣)↗[GO!]y]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerCLI</tag>
        <tag>VS Code</tag>
        <tag>PowerShell ISE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PowerCLI实现自动部署VM]]></title>
    <url>%2F2017%2F12%2F21%2Fpowercli_vmdeploy%2F</url>
    <content type="text"><![CDATA[最近沉迷于一项工作任务——PowerCLI实现自动部署VM，参考了大神的作品，按照实际工作环境做了修改。足足600行代码，实在繁琐，所以这里就不贴代码了，直接扔在Gist上了。现在的心情如图。通过这个脚本，顺便捡起了10年前学的powershell，这里借着这个脚本的实现总结下几个脚本里用到的技巧。 脚本功能概述脚本大致完成下面几件事情： 读取csv文件——csv文件例子也放在Gist上了。里面带数字的列是可以增加的，比如例子只有disk1,disk2，可以继续加上disk3,disk4,disk5等等（如果新VM须要更多硬盘的话） VM部署——会根据csv文件列出的每一个VM开启一个powershell job进行部署 VM创建包括下面这些后续任务： Customize——检查customize状态 VM Tools升级——如果是windows则自动完成vmtools升级 硬件配置——根据csv要求的硬件配置VM GuestOS脚本——执行guestOS脚本（我里面写了windows guest os的设置IP和加域的脚本，理论上应该可以添加任意想在vm里运行的任务） 产生日志——包括两个层面的日志： 跟踪Job状态——脚本定时检查VM部署Job的状态，并输出日志 VM部署日志——各个VM部署Job产生当前部署任务的进度总之，完成的任务很大程度是基于工作环境须要的，所以下面主要还是看看脚本里值得笔记的几个powershell使用技巧吧。 ScriptBlock脚本里所有实际部署操作都是通关过start-job调用scriptblock完成的，所以脚本大部分（103-491行）就是定义了个scriptblock，然后里面还罪恶的嵌套了几个scriptblock，比较厉害的就是那个$continue（228-238行），返回一个bool值放在while条件里，把复杂的判断条件封装了起来。scriptblock定义的语法如下：1234567$example_scriptblock=&#123; $a="hello" $b="world" return "$a $b!"&#125;Write-Host $example_scriptblock #this will output above block definitionWrite-Host (&amp; $example_scriptblock) #this will output "hello world!" 上面使用&amp;符号执行scriptblock，像start-job这类命令直接调用ScriptBlock变量即可。 另外，scriptblock也是可以加参数的。用法与函数和脚本自身的参数定义 通过hash跟踪任务hash真的越用越好用，脚本里多处使用： start-job放进一个hash里，用来跟踪Job状态 新建VM放进hash里，跟踪vm创建状态 升级vmtools任务放进hash，跟踪升级成功状态 配置硬件的任务放进hash里，跟踪硬件配置是否成功 hash一般定义和使用这里就不赘述了，这里写个例子用来把vmhost放进hash12$hosthash=@&#123;&#125;get-vmhost|%&#123;$hosthash[$_.name]=$_.NumCpu&#125; 这里还用到了%{}符号，其实就是把管道前输出的做foreach，通过这个方法把hash内容赋值。 一般来讲，获取value比较方便，这里有个方法通过value来获取key的1($hosthash.GetEnumerator()|where&#123;$_.value -eq 24&#125;).name 自定义对象脚本里用了两种方式自定义对象。第一种规规矩矩的用New-Object PSObject和Add-Member创建。12$job_progress = New-Object PSObject$job_progress | Add-Member -Name "PWROK" -Value 0 -MemberType NoteProperty 第二种通过管道1$obj = "" | select VM,CustomizationStatus,StartVMEvent 总体来说，都比较灵活，后期使用还是要当心点，切记“动态类型一时爽，代码重构火葬场”。 其他总结 System.Collections.ArrayList和@()符号定义的list还是有不同的，脚本里的220行和226行用到 Job通过一个自定义变量产生的csv来跟踪状态，并拿到对应值可以用write-progress画进度条（610-647行） 用[Diagnostics.Stopwatch]::StartNew()监控总体任务耗时（572,659,660行） 脚本执行不下去的话可以用get-job看job状态，receive-job获得job交互信息（比如执行guest os script时如果须要输入guest os用户名密码，那么就会须要弹出对话框交互） Invoke-VMScript命令传送的不是花括号定义的scriptblock，而是单引号定义的字符串，具体定义规则参考vmware technote，前提条件不少，也建议参考大牛博客写的使用方法 另外，本来还打算继续写基于vcenter的vm部署脚本。（大神原作是基于cluster的，而且会按照cluster内host数量均衡的部署）好吧，总之现在先打算弃坑了，又接到新的任务了 &lt;(￣︶￣)↗[GO!]]]></content>
      <categories>
        <category>学习</category>
        <category>VMware</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
        <tag>PowerCLI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[至今使用的插件列表]]></title>
    <url>%2F2017%2F11%2F15%2Fpluginlist%2F</url>
    <content type="text"><![CDATA[先播一段程序小猴奚有米的视频，嘿&lt;(￣︶￣)↗[GO!]A monkey hitting keys at random on a typewriter keyboard for an infinite amount of time will almost surely type a given text, such as the complete works of William Shakespeare. Émile BorelInfinite monkey theorem 七牛图床下载安装1npm install hexo-qiniu-sync --save 修改_config.yml123456789101112131415161718qiniu: offline: false sync: true bucket: edxi access_key: AccessKey secret_key: SecretKey dirPrefix: static urlPrefix: http://ovdqer2rp.bkt.clouddn.com/static #up_host: http://upload.qiniu.com local_dir: static update_exist: true image: folder: images extend: js: folder: js css: folder: css 图片用PNGGauntlet无损压缩一下。然后放在hexo站点目录的static/image下（建议按blog名再建个目录，比如hexosite/static/image/blogname/cover.png），hexo g的时候会同步图片。使用方式：1&#123;% qnimg blogname/cover.png %&#125; asciinema录屏下载安装1npm install --save hexo-tag-asciinema 先按照asciinema官方文档完成录屏。录制完成后记录video_id，比如下面这段录制的video_id就是IGFqHfw0zbe2VckMU9niLY0mB12345678910# asciinema rec~ Asciicast recording started.~ Hit Ctrl-D or type "exit" to finish.# [root@ansible01 _posts]# echo Hello xiyoumiHello xiyoumi[root@ansible01 _posts]# exit~ Asciicast recording finished.~ Press &lt;Enter&gt; to upload, &lt;Ctrl-C&gt; to cancel.https://asciinema.org/a/IGFqHfw0zbe2VckMU9niLY0mB 引用这个video就是1&#123;% asciinema video_id %&#125; flowchart流程图下载安装1npm install --save hexo-filter-flowchart 配置_config.yml添加下面这段：1234flowchart: # raphael: # optional, the source url of raphael.js # flowchart: # optional, the source url of flowchart.js options: # options used for `drawSVG` 使用的时候直接按照flowchar.js官网的语法写好流程就行 添加脚注下载安装：1npm install hexo-reference --save 使用方法就直接参考github上的README.md吧，这里不再赘述。 Tag Plugins这篇博客开头的youku是iframe，开头的猴子引言是blockquote，两者使用的是Hexo默认安装的Tag PluginTag的使用方法如下： iframeTag ported from Octopressiframe help1&lt;iframe src=&quot;url&quot; width=&quot;[width][height]&quot; height=&quot;300&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; blockquote 123&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125; 另外，上面的iframe使用方法用codeblock实现的，哼哼( •̀ ω •́ )✧ 关于猴子~最后，关于猴子，如果有兴趣研究的话~https://en.wikipedia.org/wiki/Infinite_monkey_theorem]]></content>
      <categories>
        <category>学习</category>
        <category>建站</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix学习笔记--CentOS7安装selinux修改（转）]]></title>
    <url>%2F2017%2F11%2F08%2FZabbix-selinuxIssue%2F</url>
    <content type="text"><![CDATA[在CentOS 7安装Zabbix 3.4后，SELINUX开启，启动Zabbix-Server报错。经查为Zabbix 3.4已知故障[1]记录故障现象及解决方法（参考Baleam的博客[2]） 故障现象systemd报错如下：1234567891011[root@ansible02 ~]# systemctl status zabbix-server.service● zabbix-server.service - Zabbix Server Loaded: loaded (/usr/lib/systemd/system/zabbix-server.service; enabled; vendor preset: disabled) Active: activating (auto-restart) (Result: exit-code) since Wed 2017-11-08 19:57:09 CST; 6s ago Process: 24278 ExecStop=/bin/kill -SIGTERM $MAINPID (code=exited, status=1/FAILURE) Process: 24227 ExecStart=/usr/sbin/zabbix_server -c $CONFFILE (code=exited, status=0/SUCCESS) Main PID: 24229 (code=exited, status=0/SUCCESS)Nov 08 19:57:09 ansible02.mylab.com systemd[1]: zabbix-server.service: control process exited, code=exited status=1Nov 08 19:57:09 ansible02.mylab.com systemd[1]: Unit zabbix-server.service entered failed state.Nov 08 19:57:09 ansible02.mylab.com systemd[1]: zabbix-server.service failed. 开启/etc/zabbix/zabbix_server.conf1LogFile=/var/log/zabbix/zabbix_server.log 报错日志如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@ansible02 ~]# more /var/log/zabbix/zabbix_server.log 22072:20171107:055224.207 Starting Zabbix Server. Zabbix 3.4.3 (revision 73588). 22072:20171107:055224.207 ****** Enabled features ****** 22072:20171107:055224.207 SNMP monitoring: YES 22072:20171107:055224.207 IPMI monitoring: YES 22072:20171107:055224.207 Web monitoring: YES 22072:20171107:055224.207 VMware monitoring: YES 22072:20171107:055224.207 SMTP authentication: YES 22072:20171107:055224.207 Jabber notifications: YES 22072:20171107:055224.207 Ez Texting notifications: YES 22072:20171107:055224.207 ODBC: YES 22072:20171107:055224.207 SSH2 support: YES 22072:20171107:055224.207 IPv6 support: YES 22072:20171107:055224.207 TLS support: YES 22072:20171107:055224.207 ****************************** 22072:20171107:055224.207 using configuration file: /etc/zabbix/zabbix_server.conf 22072:20171107:055224.229 current database version (mandatory/optional): 03040000/03040005 22072:20171107:055224.229 required mandatory version: 03040000 22072:20171107:055224.262 server #0 started [main process] 22083:20171107:055224.287 server #8 started [discoverer #1] 22084:20171107:055224.300 server #9 started [history syncer #1] 22080:20171107:055224.301 server #5 started [housekeeper #1] 22077:20171107:055224.301 server #2 started [alerter #1] 22078:20171107:055224.302 server #3 started [alerter #2] 22079:20171107:055224.302 server #4 started [alerter #3] 22082:20171107:055224.302 server #7 started [http poller #1] 22086:20171107:055224.303 server #11 started [history syncer #3] 22076:20171107:055224.303 server #1 started [configuration syncer #1] 22081:20171107:055224.304 server #6 started [timer #1] 22085:20171107:055224.304 server #10 started [history syncer #2] 22087:20171107:055224.305 server #12 started [history syncer #4] 22089:20171107:055224.305 server #14 started [proxy poller #1] 22091:20171107:055224.310 server #16 started [task manager #1] 22093:20171107:055224.310 server #18 started [poller #2] 22095:20171107:055224.316 server #20 started [poller #4] 22090:20171107:055224.319 server #15 started [self-monitoring #1] 22092:20171107:055224.320 server #17 started [poller #1] 22094:20171107:055224.324 server #19 started [poller #3] 22096:20171107:055224.328 server #21 started [poller #5] 22088:20171107:055224.331 server #13 started [escalator #1] 22106:20171107:055224.360 server #22 started [unreachable poller #1] 22107:20171107:055224.374 server #23 started [trapper #1] 22111:20171107:055224.378 server #27 started [trapper #5] 22114:20171107:055224.382 server #30 started [preprocessing manager #1] 22114:20171107:055224.383 cannot start preprocessing service: Cannot bind socket to "/var/run/zabbix/zabbix_server_preprocessing.sock": [13] Permission denied. 22072:20171107:055224.385 One child process died (PID:22114,exitcode/signal:1). Exiting ... 22072:20171107:055226.387 syncing history data... 22072:20171107:055226.387 syncing history data done 22072:20171107:055226.387 syncing trend data... 22072:20171107:055226.387 syncing trend data done 22072:20171107:055226.387 Zabbix Server stopped. Zabbix 3.4.3 (revision 73588). 其中发现关键报错1cannot start preprocessing service: Cannot bind socket to "/var/run/zabbix/zabbix_server_preprocessing.sock": [13] Permission denied. 修复方法通过下载并导入官方支持提供的selinux模块包可以修复12345678910111213141516171819# getsebool -a | grep zabbixhttpd_can_connect_zabbix --&gt; onzabbix_can_network --&gt; off# setsebool -P zabbix_can_network on# systemctl stop mysqld# systemctl stop zabbix-server# systemctl stop zabbix-agent# yum install -y policycoreutils-python# wget -O zabbix_server_add.te https://support.zabbix.com/secure/attachment/53320/53320_zabbix_server_add.te –no-check-certificate# checkmodule -M -m -o zabbix_server_add.mod zabbix_server_add.te# semodule_package -o zabbix_server_add.pp -m zabbix_server_add.mod# semodule -i zabbix_server_add.pp# systemctl restart zabbix-server;# systemctl restart zabbix-agent# systemctl start mysqld# systemctl start zabbix-server# systemctl start zabbix-agent 参考 1.issue:https://www.zabbix.com/documentation/3.4/manual/installation/upgrade_notes_340#possible_issues_with_selinux ↩2.https://baleam.com/2017/10/zabbix-zabbix_server_alerter-sock-13-permission-denied/ ↩]]></content>
      <categories>
        <category>学习</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iTop学习笔记--REST集成]]></title>
    <url>%2F2017%2F11%2F06%2FiTop-REST%2F</url>
    <content type="text"><![CDATA[早先有同事通过直接修改iTop数据库实现集成，由于这种方式略感粗暴（一旦类对象变化或版本升级等原因导致数据库表结构变化，比较容易出现问题），所以测试了iTop官方安装文档推荐的REST/JSON集成方式，这里使用python实现。 POST参数要调用对应的action，通过下面几个参数给/webservices/rest.php Argument Description Defaut value version Version of the API. It is a way to make sure that the targetted iTop server can deliver some functionality, and it ensures stability for your scripts: as long as a version is available, the operations will remain unchanged, with the exception of the following cases: bug fixes, modification in the returned messages, new elements into the returned JSON structure. - auth_user User login - auth_pwd User password - json_data Structure containing all the information required to process your request. In particular, the requested operation is given here. callback If set, then JSON-P (JSON with padding) is used 在实际使用参数时，须要注意： 传递auth_user和auth_pwd须要在配置文件/conf/production/config-itop.php开启url 1'allowed_login_types' =&gt; 'form|basic|external|url', 所有参数整体作为dictionary传递（并做urlencode），在整个dictionary中的json_data须要事先指定为JSON类型 具体操作都是由json_data参数内完成，可以使用”operation”: “list_operations”列出所有支持的operation python实现这里测试实现了直接脚本里写了一个参数列表，POST到iTop实现ticket创建。生产环境可以通过传递相应参数来实现不通内容的传递。 1234567891011121314151617181920212223242526272829303132'''Created on Nov 6, 2017@author: edxi'''import jsonimport urllib.request, urllib.error, urllib.parsedata = dict(auth_user="admin", auth_pwd="itopadminpass", version="1.3", json_data=json.dumps(&#123; "operation": "core/create", "comment": "Synchronization from python script", "class": "UserRequest", "output_fields": "id, friendlyname", "fields": &#123; "org_id": "SELECT Organization WHERE name = \"MyOrg\"", "caller_id": &#123; "name": "xi", "first_name": "erde", &#125;, "title": "Got a problem!", "description": "It's generated by python script" &#125;&#125;))req = urllib.request.Request('http://192.168.145.130/webservices/rest.php', data=urllib.parse.urlencode(data).encode("utf-8")) # this will make the method "POST"response = urllib.request.urlopen(req)print(response.read().decode('utf-8'))]]></content>
      <categories>
        <category>学习</category>
        <category>iTop</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>iTop</tag>
        <tag>REST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iTop学习笔记--安装和初始化配置]]></title>
    <url>%2F2017%2F10%2F24%2FiTop-initSetup%2F</url>
    <content type="text"><![CDATA[大致步骤就是按照iTop官方安装文档，过程中略有小坑，这里笔记一下。 itop相关包安装123yum install httpdyum install mysql mysql-serveryum install php php-mysql php-mcrypt php-xml php-cli php-soap php-ldap graphviz php-gd 修改上传图片大小(/etc/php.ini和/etc/my.cnf)https://wiki.openitop.org/doku.php?id=2_3_0:install:php_and_mysql_configuration 修改httpd的selinuxiTop解压到/var/www/html/itop，目录设置: 12chown -R apache:apache /var/www/html/itopchcon -R -t httpd_sys_rw_content_t /var/www/html/itop 安装向导避免mysql php mismatch报错12yum remove php-mysqlyum install php-mysqlnd 安装OPcache加速php官方文档仍旧写的是遗弃项目APC，这里改用OPcache https://laravel-china.org/topics/301/using-opcache-to-enhance-the-performance-of-the-php-55-program http://php.net/manual/zh/opcache.installation.php1yum install php-pecl-zendopcache 检查itop配置php，删除里面不需要的翻译dictionary，以免被cache（’dictionaries’ =&gt; array里） 检查mysql key cache和query cache1234show status like &apos;key_reads%&apos;; -- key_reads / key_read_requests应该小于0.1%，否则加大key_buffer_sizeshow variables like &apos;key_buffer_size&apos;;show status like &apos;Qcache%&apos;; -- mysql5.7.20开始遗弃这个功能，http://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/，mariaDB还可以用SHOW VARIABLES LIKE &apos;%query_cache%&apos;; 设置cron.php修改 /etc/itop/params 12auth_user=adminauth_pwd=adminpassword 修改 /etc/crontab 1*/1 * * * * root /usr/bin/php /var/www/html/webservices/cron.php --param_file=/etc/itop/params &gt;&gt;/var/log/itop-cron.log 2&gt;&amp;1]]></content>
      <categories>
        <category>学习</category>
        <category>iTop</category>
      </categories>
      <tags>
        <tag>iTop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible学习笔记--python编写读取excel的dynamic inventory]]></title>
    <url>%2F2017%2F10%2F10%2FAnsible-excel-inventory%2F</url>
    <content type="text"><![CDATA[Ansible提供了自己写脚本实现获取inventory的方法，直接通过github下载ansible源码，在/ansible/contrib/inventory目录里有不少现成的dynamic inventory，比如ec2、cobbler、openstack等等，可以直接从对应系统读取ansible须要管理的主机信息。这里要实现得dynamic inventory是从excel里读取主机信息（可能因为功能太low了，这么多contribute里面居然没有，于是自己写脚本实现一个）。 Dynamic Inventory介绍官方文档大致介绍了用途，这里再简单赘述一下。 Dynamic Inventory结构参照官方文档，dynamic inventory结构为一个JSON格式，里面分为分组字典和_meta字典两部分。 分组字典分组即主机列表的分组，可以包括对应分组的变量，官方示例如下： 123456789101112131415161718&#123; "databases": &#123; "hosts": ["host1.example.com", "host2.example.com"], "vars": &#123; "a": true &#125; &#125;, "webservers": ["host2.example.com", "host3.example.com"], "atlanta": &#123; "hosts": ["host1.example.com", "host4.example.com", "host5.example.com"], "vars": &#123; "b": false &#125;, "children": ["marietta", "5points"] &#125;, "marietta": ["host6.example.com"], "5points": ["host7.example.com"]&#125; 可以使用all分组存放所有其他分组或主机 _meta字典_meta字典作用是存放所有主机的变量，JSON格式如下： 12345678910111213141516&#123; # results of inventory script as above go here # ... "_meta": &#123; "hostvars": &#123; "moocow.example.com": &#123; "asdf" : 1234 &#125;, "llama.example.com": &#123; "asdf": 5678 &#125; &#125; &#125;&#125; Dynamic Inventory调用两种inventory pluginAnsible在使用Inventory时会尝试调用两种plugin，一种默认使用的ini plugin，另一种就是dynamic inventory使用的script plugin。所以在使用dynamic inventory的时候，本质上并不需要特别指定目前使用的inventory文件时ini还是一个script文件，和调用ini的inventory完全一样，用以下方式指定dynamic inventory脚本文件名即可： 命令参数方式——例如 ansible -i xl-inventory.py webserver:dbserver -m ping，命令里面直接通过-i指定xl-inventory.py这个脚本，每次调用该脚本生成JSON字典格式的inventory。 config文件——例如配置/etc/ansible/ansible.cfg文件的inventory = /etc/ansible/xl-inventory.py 环境变量——例如export ANSIBLE_INVENTORY=~/xl-inventory.py 脚本参数作为输出JSON字典的脚本，要求提供两个参数： list——用来返回整个JSON字典。 host——用来返回指定host的variable。 两个参数都是强制要求的，但是由于使用_meta已经可以为每个Host提供variable，所以这时候host实际上可以返回个空字典。 Dynamic Inventory脚本知道了dynamic inventory结构后，就编写脚本输出该JSON格式。（应该输出yaml格式也是可以的，我这里没有实际测试过） excel inventory示例这里用python写了脚本，功能是 把excel读取出来 指定某列为主机 其他列为meta的host vars 而且可以将某些列作为分组组名 组名会读取指定group vars目录对应的分组yaml文件 上面这些excel的信息通过一个ini文件指定 最终组成一个dict输出 excel表格示例如下： IP Host Name OS Version Status Function 192.168.1.10 host1 CentOS 6.9 Active ELKstack 192.168.1.11 host2.test.lab CentOS 7 Inactive ELKstack 192.168.1.12 host3.test.lab Windows 2012R2 Active ADDS 假设指定IP列为inventory的主机，OS Version、Status和Function三列都作分组，并且有ELKstack和Windows 2012R2两个group vars文件，期望结果示例JSON如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&#123; "all": &#123; "hosts": [ "192.168.1.10", "192.168.1.11", "192.168.1.12" ], "vars": &#123;&#125; &#125;, "Active": &#123; "hosts": [ "192.168.1.10", "192.168.1.12" ], "vars": &#123;&#125; &#125;, "Inactive": &#123; "hosts": [ "192.168.1.11" ], "vars": &#123;&#125; &#125;, "CentOS 6.9": &#123; "hosts": [ "192.168.1.10" ], "vars": &#123;&#125; &#125;, "CentOS 7": &#123; "hosts": [ "192.168.1.11" ], "vars": &#123;&#125; &#125;, "Windows 2012R2": &#123; "hosts": [ "192.168.1.12" ], "vars": &#123; "ansible_winrm_realm": "test.lab", "ansible_winrm_transport": "kerberos", "ansible_port": 5986, "ansible_connection": "winrm", "ansible_winrm_server_cert_validation": "ignore" &#125; &#125;, "ELKstack": &#123; "hosts": [ "192.168.1.10", "192.168.1.11" ], "vars": &#123; "proxyserver": "192.168.1.80", "proxyport": 8080, "resolv_nameservers": [ "192.168.1.12", "8.8.8.8" ] &#125; &#125;, "ADDS": &#123; "hosts": [ "192.168.1.12" ], "vars": &#123;&#125; &#125;, "_meta": &#123; "hostvars": &#123; "192.168.1.10": &#123; "IP": "192.168.1.10", "Host_Name": "host1", "OS_Version": "CentOS 6.9", "Status": "Active", "Function": "ELKstack" &#125;, "192.168.1.11": &#123; "IP": "192.168.1.11", "Host_Name": "host2.test.lab", "OS_Version": "CentOS 7", "Status": "Inactive", "Function": "ELKstack" &#125;, "192.168.1.12": &#123; "IP": "192.168.1.12", "Host_Name": "host3.test.lab", "OS_Version": "Windows 2012R2", "Status": "Active", "Function": "ADDS" &#125; &#125; &#125;&#125; 脚本程序流程 脚本代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# -*- coding: utf-8 -*-import argparseimport configparserimport jsonimport xlrdimport osimport yamldef open_excel(file): try: data = xlrd.open_workbook(file) return data except Exception as e: print(str(e))def inventory_group(ws, inventory=&#123;&#125;, host_column=0, group_column=-1): # 功能——按指定列分组主机 """ 实现——先初始化该列的hash，初始化时如该组名在group_vars_file_list里有，同时初始化vars 再逐行将主机列的值append到list里 :param ws: excel的worksheet，作为输入数据源 :param inventory: 最终要输出的inventory字典，将数据添加到该字典 :param host_column: inventory的Host或IP列号 :param group_column: 如果须要按照某列分组，提供分组使用的列号 :return: 添加excel数据后的Inventory """ if group_column == -1: inventory['all'] = &#123;'hosts': [], 'vars': &#123;&#125;&#125; for i in range(ws.nrows - 1): inventory['all']['hosts'].append(ws.cell_value(i + 1, host_column)) else: group_vars_file_list = next(os.walk(config['Excel Inventory']['group_vars_dir']))[2] for i in ws.col_values(group_column, 1): if i in group_vars_file_list: inventory[i] = &#123;'hosts': [], 'vars': yaml.load(open(config['Excel Inventory']['group_vars_dir']+'/'+i))&#125; else: inventory[i] = &#123;'hosts': [], 'vars': &#123;&#125;&#125; for i in range(ws.nrows - 1): inventory[ws.cell_value(i + 1, group_column)]['hosts'].append(ws.cell_value(i + 1, host_column)) return inventorydef ExcelInventory(): wb = xlrd.open_workbook(filename=config['Excel Inventory']['file_name']) ws = wb.sheet_by_name(config['Excel Inventory']['sheet_name']) column_hash = &#123;&#125; for i in range(ws.ncols): column_hash[ws.cell_value(0, i)] = i host_column_name = column_hash[config['Excel Inventory']['host_column_name']] # 初始化一个包括所有主机的all group # inventory_hash = &#123;ws.cell_value(0, host_column_name): &#123;'hosts': host_list, 'vars': &#123;&#125;&#125;&#125; inventory_hash = inventory_group(ws, host_column=host_column_name) # 按照Group Column例举的列分组 for item in config['Group Column']: inventory_hash = inventory_group(ws, host_column=host_column_name, group_column=column_hash[item]) # 功能——将IP对应的行的所有列作为_mata的hostvars值 # 实现——外层循环将每一行的IP作为key内层循环的hash作为value，内层循环将该列的第一行作为key当前行作为value host_list = ws.col_values(host_column_name, start_rowx=1) hostvars = &#123;&#125; for i in range(ws.nrows - 1): varscollumn = &#123;&#125; for j in range(ws.ncols): varscollumn[ws.cell_value(0, j).replace(' ', '_')] = ws.cell_value(i + 1, j) hostvars[host_list[i]] = varscollumn inventory_hash['_meta'] = &#123;'hostvars': hostvars&#125; return inventory_hashif __name__ == "__main__": parser = argparse.ArgumentParser() parser.add_argument('-l', '--list', help='hosts list', action='store_true') parser.add_argument('-H', '--host', help='hosts vars') args = vars(parser.parse_args()) config = configparser.ConfigParser() config.optionxform = str config.read('./xl-inventory.ini') if args['list']: print(json.dumps(ExcelInventory(), indent=4)) elif args['host']: print(json.dumps(&#123;'_meta': &#123;'hostvars': &#123;&#125;&#125;&#125;)) else: parser.print_help() 配置文件123456789101112[Excel Inventory]file_name = ./sample.xlsxsheet_name = Sheet1host_column_name = IPgroup_vars_dir = .# Column(s) which need to define group. Only need key. Value will be ignored.[Group Column]# List only column nameStatus =OS Version =Function = st=>start: Start|past e=>end: End op1=>operation: 从ini初始化配置|past op2=>operation: 打印帮助|current op3=>operation: 读取excel分组|current op4=>operation: 添加meta到dict|current sub1=>subroutine: 添加主机分组dict|invalid cond=>condition: 脚本参数 使用--list|approved c2=>condition: 脚本参数 使用--host|rejected c3=>condition: 主机分组 添加完成?|approved io=>inputoutput: 输出空JSON|request io2=>inputoutput: 输出dict到JSON|request st->op1(right)->cond cond(no, right)->c2 cond(yes)->op3 op3->c3 c3(no, left)->sub1 sub1(left)->op3 c3(yes)->op4->io2->e c2(yes)->io->e c2(no)->op2->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>学习</category>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible学习笔记--从Playbook创建Role]]></title>
    <url>%2F2017%2F10%2F04%2FAnsible-PlaybookToRole%2F</url>
    <content type="text"><![CDATA[下面以一个现成的playbook为例，将其内容分解并编排成一个role。 整个步骤的终端录屏 现有playbook12345678910111213141516171819202122232425262728293031323334353637383940414243- hosts: localhost sudo: true vars: baserepo: '' updatesrepo: '' extrasrepo: ''# Task setup local repositories tasks: - name: Remove repository (and clean up left-over metadata) yum_repository: name: packages state: absent notify: yum-clean-metadata - name: Add yumserver repository template: "src=yumserver.repo dest=/etc/yum.repos.d/yumserver.repo owner=root group=root mode=0644" - name: Add epel repository with proxy yum_repository: name: epel description: EPEL YUM repo proxy: "http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123; proxyport &#125;&#125;" baseurl: http://mirrors.aliyun.com/epel/7/$basearch failovermethod: priority gpgcheck: no when: proxyserver is defined and proxyport is defined and proxyserver != '' and proxyport != '' - name: Add epel repository without proxy yum_repository: name: epel description: EPEL YUM repo baseurl: http://mirrors.aliyun.com/epel/7/$basearch failovermethod: priority gpgcheck: no when: proxyserver is not defined proxyserver == '' tags: epel_repo# Handler clean yum metadata cache handlers: - name: yum-clean-metadata command: yum clean metadata args: warn: no 上面playbook的作用是设置yum repository。 除了hosts以外，大致分成三个部分： vars——指定了playbook须要用到的变量 tasks——具体playbook运行的module，具体执行了 先清理package repository并提醒handler执行metadata清理 通过template module设置的base/updates/extras repository 用yum_repository module设置epel handlers——定义了作为handler被调用的module 这里在tasks里有个template module，对应的template如下： 12345678910111213141516171819202122232425262728293031323334353637383940[base]name=CentOS-$releasever - Base&#123;% if baserepo is defined and baserepo != &apos;&apos; %&#125;baseurl=&#123;&#123; baserepo &#125;&#125;&#123;% else %&#125;mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra&#123;% endif %&#125;gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7&#123;% if proxyserver is defined and proxyserver != &apos;&apos; and proxyport is defined and baserepo == &apos;&apos; %&#125;proxy=http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123;proxyport&#125;&#125;&#123;% endif %&#125;#released updates[updates]name=CentOS-$releasever - Updates&#123;% if updatesrepo is defined and updatesrepo != &apos;&apos; %&#125;baseurl=&#123;&#123; updatesrepo &#125;&#125;&#123;% else %&#125;mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra&#123;% endif %&#125;gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7&#123;% if proxyserver is defined and proxyserver != &apos;&apos; and proxyport is defined and updatesrepo == &apos;&apos; %&#125;proxy=http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123;proxyport&#125;&#125;&#123;% endif %&#125;#additional packages that may be useful[extras]name=CentOS-$releasever - Extras&#123;% if extrasrepo is defined and extrasrepo != &apos;&apos; %&#125;baseurl=&#123;&#123; extrasrepo &#125;&#125;&#123;% else %&#125;mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra&#123;% endif %&#125;gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7&#123;% if proxyserver is defined and proxyserver != &apos;&apos; and proxyport is defined and extrasrepo == &apos;&apos; %&#125;proxy=http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123;proxyport&#125;&#125;&#123;% endif %&#125; 创建role创建目录结构role的固定目录结构如下 12345678910111213141516171819[root@ansible01 examplePlaybook]# mkdir yumrepo [root@ansible01 examplePlaybook]# # this is the role main directory[root@ansible01 examplePlaybook]# cd yumrepo[root@ansible01 yumrepo]# mkdir tasks[root@ansible01 yumrepo]# mkdir handlers[root@ansible01 yumrepo]# mkdir defaults[root@ansible01 yumrepo]# mkdir vars[root@ansible01 yumrepo]# mkdir files[root@ansible01 yumrepo]# mkdir templates[root@ansible01 yumrepo]# mkdir meta[root@ansible01 yumrepo]# lltotal 0drwxr-xr-x. 2 root root 6 Oct 4 15:47 defaultsdrwxr-xr-x. 2 root root 6 Oct 4 15:47 filesdrwxr-xr-x. 2 root root 6 Oct 4 15:47 handlersdrwxr-xr-x. 2 root root 6 Oct 4 15:47 metadrwxr-xr-x. 2 root root 6 Oct 4 15:47 tasksdrwxr-xr-x. 2 root root 6 Oct 4 15:47 templatesdrwxr-xr-x. 2 root root 6 Oct 4 15:47 vars 设置默认变量创建defaults目录里的main.yml用于设置默认变量。 在这个例子里，直接把playbook里用到的几个变量复制进去。 设置tasks创建tasks目录里的main.yml用于执行roles所调用的任务。 在这个例子里，直接把playbook里用到的几个任务复制了进去。 也可以讲不同功能的任务单独写成yml文件，然后通过在main.yml里使用include来调用（并可以使用when条件判断使用哪个任务，还可以使用tags方便在执行时调用对应功能的任务） 设置handlers创建handlers目录里的main.yml用于执行tasks所调用的handler。 在这个例子里，直接把playbook里用到的handler复制了进去。 复制template文件由于原有playbook使用到template module，所以须要把roles使用的template文件yumserver.yml复制到template目录。 测试role通过上面改写，自建的role已经完成，写一个简单的playbook用来测试 123- hosts: localhost roles: - yumrepo 执行playbook查看结果 123456789101112131415161718192021[root@ansible01 examplePlaybook]# ansible-playbook test.ymlPLAY [localhost] ******************************************************************************************************TASK [Gathering Facts] ************************************************************************************************ok: [localhost]TASK [yumrepo : Remove repository (and clean up left-over metadata)] **************************************************ok: [localhost]TASK [yumrepo : Add yumserver repository] *****************************************************************************changed: [localhost]TASK [yumrepo : Add epel repository with proxy] ***********************************************************************skipping: [localhost]TASK [yumrepo : Add epel repository without proxy] ********************************************************************ok: [localhost]PLAY RECAP ************************************************************************************************************localhost : ok=4 changed=1 unreachable=0 failed=0 可以修改测试playbook，加上参数以覆盖roles的默认参数 12345- hosts: localhost vars: baserepo: "http://repo.aliyun.com/yum/" roles: - yumrepo 再次执行就会按照上述不同的参数修改repository了。 总结大致总结下，role的目的是为了可以在各种环境下重用，把 vars, tasks, handlers等等playbook的组成元素放到固定的目录结构里。 更加详细的使用方法当然还是要参考了官方文档。 纸上得来终觉浅，绝知此事要躬行。]]></content>
      <categories>
        <category>学习</category>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿德和有米写故事--github使用案例]]></title>
    <url>%2F2017%2F08%2F31%2Fade_xiyoumi_write_story_github_example%2F</url>
    <content type="text"><![CDATA[故事梗概故事是这样滴 ade心血来潮新建了个github的repo(仓库)， 然后在repo里乱七八糟的写了点东西后提交(commit)进repo， 好奇的xiyoumi小朋友发现了这个repo，于是把repo在自己的github上做了个副本(fork)， xiyoumi小朋友把里面的东西做了点修改，也做了自己的提交， xiyoumi小朋友想把自己改的东西也合并到ade的repo里，于是提交了pull request， ade看了下pull request，觉得修改的不错，于是就合并进了repo， xiyoumi小朋友大受鼓舞，又修改了好多东西，并再次提交pull request， ade看到这次的pull request，也不知道这样改好不好，于是ade索性新建了个test分支(branch)，并在pull request里留言告诉xiyoumi，让他合并到这个分支， 于是xiyoumi小朋友重新提交了pull request，要求把合并到test分支里， ade愉快的合并了这个pull request，并且不久后把这个分支也合并进了主干(master分支)。 剧情详情好吧，具体来看看这个故事的每一段都做了点啥 ade心血来潮新建了个github的repo(仓库)， 然后在repo里乱七八糟的写了点东西后提交(commit)进repo，1234567891011121314151617[ade@~]$git init storyInitialized empty Git repository in /home/ade/story/.git/[ade@~]$cd story[ade@story]$git remote add origin git@github.com:edxi/story.git[ade@story]$echo "this is a story repository" &gt;&gt; README.md[ade@story]$git add -A[ade@story]$git commit -m "first commit"[master (root-commit) 5a98272] first commit 1 file changed, 1 insertion(+) create mode 100644 README.md[ade@story]$git push -u origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 225 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:edxi/story.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. 好奇的xiyoumi小朋友发现了这个repo，于是把repo在自己的github上做了个副本(fork)， xiyoumi小朋友把里面的东西做了点修改，也做了自己的提交，123456789101112131415161718192021222324252627282930313233[xiyoumi@~]$git clone git@github.com:xiyoumi/story.gitCloning into 'story'...remote: Counting objects: 3, done.remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0Receiving objects: 100% (3/3), done.[xiyoumi@~]$cd story/[xiyoumi@story]$echo "三只小猪的故事" &gt;&gt; pigstory.md[xiyoumi@story]$echo "xiyoumi参与写作！" &gt;&gt; README.md[xiyoumi@story]$git commit -m "交作文！"[master 13d8cc2] 交作文！ 2 files changed, 2 insertions(+) create mode 100644 pigstory.md[xiyoumi@story]$git pushwarning: push.default is unset; its implicit value is changing inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git)Counting objects: 6, done.Compressing objects: 100% (3/3), done.Writing objects: 100% (4/4), 372 bytes | 0 bytes/s, done.Total 4 (delta 0), reused 0 (delta 0)To git@github.com:xiyoumi/story.git 5a98272..13d8cc2 master -&gt; master xiyoumi小朋友想把自己改的东西也合并到ade的repo里，于是提交了pull request， ade看了下pull request，觉得修改的不错，于是就合并进了repo， xiyoumi小朋友大受鼓舞，又修改了好多东西，并再次提交pull request，1234567891011121314151617181920212223242526[xiyoumi@story]$echo "三只小猪最终打败了大灰狼" &gt;&gt; pigstory.md[xiyoumi@story]$git add -A[xiyoumi@story]$git commit -m "故事有更新啦！"[master 60ab6ec] 故事有更新啦！ 1 file changed, 1 insertion(+)[xiyoumi@story]$git pushwarning: push.default is unset; its implicit value is changing inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git)Counting objects: 5, done.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 354 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:xiyoumi/story.git 13d8cc2..60ab6ec master -&gt; master ade看到这次的pull request，也不知道这样改好不好，于是ade索性新建了个test分支(branch)，并在pull request里留言告诉xiyoumi，让他合并到这个分支里 123456[ade@story]$git push origin testCounting objects: 3, done.Writing objects: 100% (3/3), 225 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:edxi/story.git * [new branch] test -&gt; test 于是xiyoumi小朋友重新提交了pull request，要求把合并到test分支里， ade愉快的合并了这个pull request，并且不久后把这个分支也合并进了主干(master分支)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[ade@story]$git branch master* test[ade@story]$git pull origin testFrom github.com:edxi/story * branch test -&gt; FETCH_HEADUpdating 5a98272..62fe9efFast-forward README.md | 1 + pigstory.md | 2 ++ 2 files changed, 3 insertions(+) create mode 100644 pigstory.md[ade@story]$git checkout masterSwitched to branch 'master'Your branch is behind 'origin/master' by 2 commits, and can be fast-forwarded. (use "git pull" to update your local branch)[ade@story]$git pull --allFetching originUpdating 5a98272..31e542bFast-forward README.md | 1 + pigstory.md | 1 + 2 files changed, 2 insertions(+) create mode 100644 pigstory.md[ade@story]$git merge test -m "Merge branch 'test'"Merge made by the 'recursive' strategy. pigstory.md | 1 + 1 file changed, 1 insertion(+)[ade@story]$git pushwarning: push.default is unset; its implicit value is changing inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git)Counting objects: 1, done.Writing objects: 100% (1/1), 210 bytes | 0 bytes/s, done.Total 1 (delta 0), reused 0 (delta 0)To git@github.com:edxi/story.git 31e542b..4804dda master -&gt; master 尾声到这里，已经知道了ade和xiyoumi是怎么通过github一起写故事了，可是似乎还没有这么简单，不久之后他们又有了新的问题： xiyoumi发现fork源的repo早就变了，怎么同步呢？ 随着越来越多的人加入故事投稿，分支和提交觉得乱糟糟的，怎么才能简洁点呢？能不能删除git log呢？ 问题的答案至今还不知晓~ 一个人走得快，一群人走得远 ——《有赞》广告词]]></content>
      <categories>
        <category>学习</category>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World!]]></title>
    <url>%2F2017%2F08%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[哈喽 世界！ o(￣▽￣)ブ这是DXC守护者第一篇! 简介建站故事​ 很久之后，又开始写博客了，这次用github page，觉得舒爽轻松很多。 ​ 20年前（暴露年龄），当时国内有个凯利网站空间，可以自己做网页上传，于是用FrontPage写了个html，隔天就在教室黑板上把网站链接写在黑板上得瑟。这算是自己最早的博客了。 ​ 之后就和大多数人一样，更新最多的是msn空间，msn空间关闭后迁移到wordpress，但因为被墙，于是索性自己买了域名和空间，直到2012年，付费两年后，看到自己其实多数更新都在微博上，于是也就放弃了。 ​ 现如今，就连微博都已经做过了一轮复兴之路，朋友圈和公众号是主流，但是作为老挨踢的情怀，自己偏偏又开始写起博客了，希望这个博客可以给工作生活带来帮助。 网站作用 首先，这是我的个人博客，我说是啥用就是啥用， (￣y▽￣)╭ Ohohoho….. 然后，我想肯定会记录些生活和学习上内容吧。 再就是，希望对日常工作有所帮助，也利用github这个厉害的平台，和DXC的小鬼们分享有用的资源。 还有就是，网站因为采用Hexo+github page建站，用markdown写博客，所以本站接受大家投稿。 DXC是什么​ 其实就是我现在工作的公司名字，但是就目前为止没人知道是什么缩写~(￣▽￣)”于是就有各种奇葩翻译： 稻香村——想要成为老字号的志向~ 大香肠——某个饥渴的同事翻译的。 地下城——这个我喜欢，有个古老的游戏叫做地下城守护者，也就命名了这个网站DXC守护者。 投稿指南​ 建站前只是想把github的gh-pages改善下，然后弄着弄着就索性开始建站了，后来最终选用github page+hexo作建站工具，站点内容可以使用markdown书写，可以用纯文本编辑器书写或markdown编辑器，然后非常欢迎大家上传到这个blog-contribute repository，我会定期更新到DXC守护者网站上的。 投稿格式​ 投稿接受markdown格式，可以参考资源列表里介绍的markdown编辑器来编辑（可以做work/pdf等格式的转换，但是会有部分格式损失，所以最好还是直接用markdown编辑器来书写）。具体书写方式也可以参考资源列表里列出的资源。 ​ （可选）此外由于采用hexo建站，所以还能接受下面这类格式作为页面头信息，类似于下面格式写在md文件最前面写好就可以了（参数都是可选的）： 1234567891011---title: 文章标题date: 2013/7/13 20:46:25categories:- 学习- gittags:- git- github- git page--- 这里列举了些参数： 参数 描述 默认值 title 标题 date 建立日期 文件建立日期 updated 更新日期 文件更新日期 comments 开启文章的评论功能 true tags 标签 categories 分类 description 文章描述 投稿方式​ 目前推荐下面集中方式上传.md文件： 最简单的方式是直接通过github的issues——可以直接在DXC守护者和blog-contribute这两个repo里写issue，然后把.md的内容黏贴上来，并注明这是篇需要投稿的文章，我看过后会把相应内容post到网站的。 如果想要以文件形式维护自己的文章列表，可以先fork blog-contribute这个repo，或者直接克隆repo后创建新文件，然后通过pull request的方式把md文件合并进来，后面的资源列表里有github使用的相关链接。收到新的pull request我会看过文章内容，然后合并进来，并post到网站。 当然也接受邮件寄送给我.md文件。&#101;&#100;&#x78;&#105;&#64;&#x6d;&#x73;&#x6e;&#x2e;&#99;&#x6f;&#109; 资源列表markdown编辑器推荐几款markdown编辑器： typora——多平台可用的编辑器，支持所见即所得的编辑，这篇就是用它写的。 Meditor.md——开源在线 Markdown 编辑器，直接在线可以编辑，所以手头没有电脑的时候，用这个写作就可以了，而且作为一个github项目，可以下载到本地，在本地使用。 iA Writer——手机上也很好用的编辑器，安卓和IOS都支持，还可以横屏编辑，搞个平板，So IBility! 另外，其实有道云笔记也很好用，也很方便在各个平台上面分享。 markdown书写 可以参考github上的markdown链接。 另外还有个的markdown cheatsheet，作为参考列表也很方便。 此外各个编辑器平台也会针对自己的帮助文档，通常会更加详细，且带有示例。 GitHub使用 个人推荐参考大V廖雪峰的官方网站。里面有浅显移动的git教程，其中包括了结合GitHub的使用方法，对入门很有帮助。 官方帮助文档当然是最全面的。]]></content>
      <categories>
        <category>学习</category>
        <category>建站</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>github</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
