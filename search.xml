<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PowerCLI IDE环境]]></title>
    <url>%2F2018%2F01%2F01%2Fpowershell_IDE%2F</url>
    <content type="text"><![CDATA[Happy New Year 2018 !!!奚有米先来送波祝福。 新的一年要继续好好学习，天天向上，在DevOps方面不断进步！ 工欲善其事，必先利其器 孔子（春秋）《论语·卫灵公》 为继续PowerShell方面的工作，这里整理起两个自己感觉非常好用的编辑器，并附上一些配置： PowerShell ISE + ISESteroids VS Code + PowerShell Extension 此外，由于经常须要写VMware PowerCLI，所以这里也附上了两个编辑器加载Module的方法。 PowerShell ISE + ISESteroids大致来讲相信多数写PowerShell都是从PowerShell ISE开始的，作为系统自带的PowerShell编辑器干净又好用（据说微软现在正在开发新的系统自带编辑器）。装上ISESteroids后，就完全是一个专业的IDE了，安装和配置也比较简单。安装方法可以直接参考ISESteroids官网的在线和离线安装步骤。这里提供两个配置的地方： 启动ISE后自动加载ISESteroids——如果启动的时候按住Ctrl键，则不会自动加载。 加载PowerCLI 6.5——启动的时候按住Alt键，才会自动加载。 两个配置我都是使用PowerShell ISE Profile，配置如下：123456789101112Add-Type -AssemblyName PresentationCoreif ([System.Windows.Input.Keyboard]::IsKeyDown('Ctrl') -eq $false)&#123; Start-Steroids&#125;if ([System.Windows.Input.Keyboard]::IsKeyDown('Alt') -eq $true)&#123; if (Get-Module -ListAvailable|Where-Object&#123;$_.name -eq "VMware.VimAutomation.Core"&#125;) &#123; Get-Module -ListAvailable VMware* | Import-Module &#125;&#125; VS Code + PowerShell Extension还记得刚学编程那会儿，Visual Studio 6.0那一大堆的CD，真是壮观~如今这个轻量却又功能强大的VS Code，用上手后非常喜欢！VS Code安装PowerShell Extension非常简单，直接在Extension里搜索PowerShell安装即可。配置上我参考了大神VSC for PowerCLI的博客。实现如下配置功能： 加载PowerCLI 6.5——启动的时候按住Alt键，才会自动加载。 Snippets——这里须要注意符号转义，比如下面的配置文件里使用\符号把PowerShell变量的$符号转义，但由于\符号本身再JSON里仍须要转义，所以最终powershell.json配置如下： 123456789101112131415&#123;"GestStat": &#123; "prefix": "PCLIStatVM", "body": [ "\\$finish = (Get-Date)", "\\$start = \\$finish.AddDays(-1)", "\\$stat = 'cpu.usage.average'", "\\$entities = Get-VM", "", "\\$stats = Get-Stat -Entity \\$entities -Stat \\$stat -Start \\$start -Finish \\$finish", "# \\$stats | Group-Object -Property EntityId" ], "description": "Sample VM statistics report"&#125;&#125; PowerShell Editor Services——自定义F1的PowerShell additional command。 配置实现使用VS Code PowerShell profile，确保VS Code的Preference-Setting (settings.json)里powershell.enableProfileLoading为默认的true。然后创建Microsoft.VSCode_profile.ps1或profile.ps1添加配置。我直接复制了大神的配置，由于不使用脚本里那么多种类的PowerCLI版本，直接修改成加载PowerCLI6.5模块。（原脚本是发现PowerCLI在注册表里的键值来确定版本，然而6.5已经不使用该键值，甚至新版本已经直接放在PowerShell Garllery上，所以不能再用原脚本的方式加载了） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Add-Type -AssemblyName PresentationCoreif ([System.Windows.Input.Keyboard]::IsKeyDown('Alt') -eq $true)&#123; if (Get-Module -ListAvailable|Where-Object&#123;$_.name -eq "VMware.VimAutomation.Core"&#125;) &#123; Get-Module -ListAvailable VMware* | Import-Module &#125;&#125;$pclihelp = &#123;$browser = 'chrome.exe'$pclisites = 'https://communities.vmware.com/community/vmtn/automationtools/powercli/content?filterID=contentstatus[published]~objecttype~objecttype[thread]','https://code.vmware.com/doc/preview?id=5975','https://code.vmware.com/apis/196/vsphere','http://blogs.vmware.com/PowerCLI','http://lucd.info'Start-Process $browser $pclisites&#125;Register-EditorCommand `-SuppressOutput `-Name 'PowerCLI.HelpSites' `-DisplayName 'PowerCLI Help Sites' `-ScriptBlock $pclihelp$pclicmdhelp = &#123;param([Parameter(Mandatory=$true)][Microsoft.PowerShell.EditorServices.Extensions.EditorContext]$context)$cmdlet = $context.CurrentFile.GetText($context.SelectedRange)$browser = 'chrome.exe'$cmdhelp = "https://code.vmware.com/doc/preview?id=5975#/doc/$($cmdlet).html" Start-Process $browser $cmdhelp &#125;Register-EditorCommand `-SuppressOutput `-Name 'PowerCLI.HelpCmdlet' `-DisplayName 'PowerCLI Cmdlet Help' `-ScriptBlock $pclicmdhelp$pscountcmdlet = &#123; param([Parameter(Mandatory=$true)][Microsoft.PowerShell.EditorServices.Extensions.EditorContext]$context) $cmdArr = @() $varArr = @() foreach($token in $context.CurrentFile.Tokens)&#123; switch($token.GetType().Name)&#123; 'StringLiteralToken'&#123; if($token.TokenFlags -eq 'CommandName')&#123; $cmdArr += $token.Value &#125; &#125; 'VariableToken'&#123; $varArr += $token.Name &#125; &#125; &#125; $cmdArr = $cmdArr | Sort-Object -Unique $varArr = $varArr | Sort-Object -Unique Write-Output "You used $($cmdArr.Count) different cmdlets" Write-Output "`t$($cmdArr -join '|')" Write-Output "You used $($varArr.Count) different variables" Write-Output "`t$($varArr -join '|')"&#125;Register-EditorCommand `-Name 'PowerShell.CountCmdletVar' `-DisplayName 'Count Cmdlets/Variables' `-ScriptBlock $pscountcmdlet 另外，VS Code实在很多可玩的地方，可以直接用在MACOS上提升逼格，可以直接可以Git（也可以用VSTS extension，须要visual studio的TS.exe），好多extension~ 比如映射VIM等其他编辑器的键盘设置，md语法检查，好多好多~好吧，Happy Coding 2018 &lt;(￣︶￣)↗[GO!]y]]></content>
      <categories>
        <category>学习</category>
        <category>PowerShell</category>
      </categories>
      <tags>
        <tag>PowerCLI</tag>
        <tag>PowerShell ISE</tag>
        <tag>VS Code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PowerCLI实现自动部署VM]]></title>
    <url>%2F2017%2F12%2F21%2Fpowercli_vmdeploy%2F</url>
    <content type="text"><![CDATA[最近沉迷于一项工作任务——PowerCLI实现自动部署VM，参考了大神的作品，按照实际工作环境做了修改。足足600行代码，实在繁琐，所以这里就不贴代码了，直接扔在GitHub上了。现在的心情如图。通过这个脚本，顺便捡起了10年前学的powershell，这里借着这个脚本的实现总结下几个脚本里用到的技巧。 脚本功能概述脚本大致完成下面几件事情： 读取csv文件——csv文件例子也放在GitHub上了。里面带数字的列是可以增加的，比如例子只有disk1,disk2，可以继续加上disk3,disk4,disk5等等（如果新VM须要更多硬盘的话） VM部署——会根据csv文件列出的每一个VM开启一个powershell job进行部署 VM创建包括下面这些后续任务： Customize——检查customize状态 VM Tools升级——如果是windows则自动完成vmtools升级 硬件配置——根据csv要求的硬件配置VM GuestOS脚本——执行guestOS脚本（我里面写了windows guest os的设置IP和加域的脚本，理论上应该可以添加任意想在vm里运行的任务） 产生日志——包括两个层面的日志： 跟踪Job状态——脚本定时检查VM部署Job的状态，并输出日志 VM部署日志——各个VM部署Job产生当前部署任务的进度总之，完成的任务很大程度是基于工作环境须要的，所以下面主要还是看看脚本里值得笔记的几个powershell使用技巧吧。 ScriptBlock脚本里所有实际部署操作都是通关过start-job调用scriptblock完成的，所以脚本大部分（103-491行）就是定义了个scriptblock，然后里面还罪恶的嵌套了几个scriptblock，比较厉害的就是那个$continue（228-238行），返回一个bool值放在while条件里，把复杂的判断条件封装了起来。scriptblock定义的语法如下：1234567$example_scriptblock=&#123; $a="hello" $b="world" return "$a $b!"&#125;Write-Host $example_scriptblock #this will output above block definitionWrite-Host (&amp; $example_scriptblock) #this will output "hello world!" 上面使用&amp;符号执行scriptblock，像start-job这类命令直接调用ScriptBlock变量即可。 另外，scriptblock也是可以加参数的。用法与函数和脚本自身的参数定义 通过hash跟踪任务hash真的越用越好用，脚本里多处使用： start-job放进一个hash里，用来跟踪Job状态 新建VM放进hash里，跟踪vm创建状态 升级vmtools任务放进hash，跟踪升级成功状态 配置硬件的任务放进hash里，跟踪硬件配置是否成功 hash一般定义和使用这里就不赘述了，这里写个例子用来把vmhost放进hash12$hosthash=@&#123;&#125;get-vmhost|%&#123;$hosthash[$_.name]=$_.NumCpu&#125; 这里还用到了%{}符号，其实就是把管道前输出的做foreach，通过这个方法把hash内容赋值。 一般来讲，获取value比较方便，这里有个方法通过value来获取key的1($hosthash.GetEnumerator()|where&#123;$_.value -eq 24&#125;).name 自定义对象脚本里用了两种方式自定义对象。第一种规规矩矩的用New-Object PSObject和Add-Member创建。12$job_progress = New-Object PSObject$job_progress | Add-Member -Name "PWROK" -Value 0 -MemberType NoteProperty 第二种通过管道1$obj = "" | select VM,CustomizationStatus,StartVMEvent 总体来说，都比较灵活，后期使用还是要当心点，切记“动态类型一时爽，代码重构火葬场”。 其他总结 System.Collections.ArrayList和@()符号定义的list还是有不同的，脚本里的220行和226行用到 Job通过一个自定义变量产生的csv来跟踪状态，并拿到对应值可以用write-progress画进度条（638-652行） 用[Diagnostics.Stopwatch]::StartNew()监控总体任务耗时（576,664,665行） 脚本执行不下去的话可以用get-job看job状态，receive-job获得job交互信息（比如执行guest os script时如果须要输入guest os用户名密码，那么就会须要弹出对话框交互） Invoke-VMScript命令传送的不是花括号定义的scriptblock，而是单引号定义的字符串，具体定义规则参考vmware technote，前提条件不少，也建议参考大牛博客写的使用方法 另外，本来还打算继续写基于vcenter的vm部署脚本。（大神原作是基于cluster的，而且会按照cluster内host数量均衡的部署）好吧，总之现在先打算弃坑了，又接到新的任务了 &lt;(￣︶￣)↗[GO!]]]></content>
      <categories>
        <category>学习</category>
        <category>VMware</category>
      </categories>
      <tags>
        <tag>PowerShell</tag>
        <tag>PowerCLI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[至今使用的插件列表]]></title>
    <url>%2F2017%2F11%2F15%2Fpluginlist%2F</url>
    <content type="text"><![CDATA[先播一段程序小猴奚有米的视频，嘿&lt;(￣︶￣)↗[GO!]A monkey hitting keys at random on a typewriter keyboard for an infinite amount of time will almost surely type a given text, such as the complete works of William Shakespeare. Émile BorelInfinite monkey theorem 七牛图床下载安装1npm install hexo-qiniu-sync --save 修改_config.yml123456789101112131415161718qiniu: offline: false sync: true bucket: edxi access_key: AccessKey secret_key: SecretKey dirPrefix: static urlPrefix: http://ovdqer2rp.bkt.clouddn.com/static #up_host: http://upload.qiniu.com local_dir: static update_exist: true image: folder: images extend: js: folder: js css: folder: css 图片用PNGGauntlet无损压缩一下。然后放在hexo站点目录的static/image下（建议按blog名再建个目录，比如hexosite/static/image/blogname/cover.png），hexo g的时候会同步图片。使用方式：1&#123;% qnimg blogname/cover.png %&#125; asciinema录屏下载安装1npm install --save hexo-tag-asciinema 先按照asciinema官方文档完成录屏。录制完成后记录video_id，比如下面这段录制的video_id就是IGFqHfw0zbe2VckMU9niLY0mB12345678910# asciinema rec~ Asciicast recording started.~ Hit Ctrl-D or type "exit" to finish.# [root@ansible01 _posts]# echo Hello xiyoumiHello xiyoumi[root@ansible01 _posts]# exit~ Asciicast recording finished.~ Press &lt;Enter&gt; to upload, &lt;Ctrl-C&gt; to cancel.https://asciinema.org/a/IGFqHfw0zbe2VckMU9niLY0mB 引用这个video就是1&#123;% asciinema video_id %&#125; flowchart流程图下载安装1npm install --save hexo-filter-flowchart 配置_config.yml添加下面这段：1234flowchart: # raphael: # optional, the source url of raphael.js # flowchart: # optional, the source url of flowchart.js options: # options used for `drawSVG` 使用的时候直接按照flowchar.js官网的语法写好流程就行 添加脚注下载安装：1npm install hexo-reference --save 使用方法就直接参考github上的README.md吧，这里不再赘述。 Tag Plugins这篇博客开头的youku是iframe，开头的猴子引言是blockquote，两者使用的是Hexo默认安装的Tag PluginTag的使用方法如下： iframeTag ported from Octopressiframe help1&lt;iframe src=&quot;url&quot; width=&quot;[width][height]&quot; height=&quot;300&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; blockquote 123&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;content&#123;% endblockquote %&#125; 另外，上面的iframe使用方法用codeblock实现的，哼哼( •̀ ω •́ )✧ 关于猴子~最后，关于猴子，如果有兴趣研究的话~https://en.wikipedia.org/wiki/Infinite_monkey_theorem]]></content>
      <categories>
        <category>学习</category>
        <category>建站</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix学习笔记--CentOS7安装selinux修改（转）]]></title>
    <url>%2F2017%2F11%2F08%2FZabbix-selinuxIssue%2F</url>
    <content type="text"><![CDATA[在CentOS 7安装Zabbix 3.4后，SELINUX开启，启动Zabbix-Server报错。经查为Zabbix 3.4已知故障[1]记录故障现象及解决方法（参考Baleam的博客[2]） 故障现象systemd报错如下：1234567891011[root@ansible02 ~]# systemctl status zabbix-server.service● zabbix-server.service - Zabbix Server Loaded: loaded (/usr/lib/systemd/system/zabbix-server.service; enabled; vendor preset: disabled) Active: activating (auto-restart) (Result: exit-code) since Wed 2017-11-08 19:57:09 CST; 6s ago Process: 24278 ExecStop=/bin/kill -SIGTERM $MAINPID (code=exited, status=1/FAILURE) Process: 24227 ExecStart=/usr/sbin/zabbix_server -c $CONFFILE (code=exited, status=0/SUCCESS) Main PID: 24229 (code=exited, status=0/SUCCESS)Nov 08 19:57:09 ansible02.mylab.com systemd[1]: zabbix-server.service: control process exited, code=exited status=1Nov 08 19:57:09 ansible02.mylab.com systemd[1]: Unit zabbix-server.service entered failed state.Nov 08 19:57:09 ansible02.mylab.com systemd[1]: zabbix-server.service failed. 开启/etc/zabbix/zabbix_server.conf1LogFile=/var/log/zabbix/zabbix_server.log 报错日志如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@ansible02 ~]# more /var/log/zabbix/zabbix_server.log 22072:20171107:055224.207 Starting Zabbix Server. Zabbix 3.4.3 (revision 73588). 22072:20171107:055224.207 ****** Enabled features ****** 22072:20171107:055224.207 SNMP monitoring: YES 22072:20171107:055224.207 IPMI monitoring: YES 22072:20171107:055224.207 Web monitoring: YES 22072:20171107:055224.207 VMware monitoring: YES 22072:20171107:055224.207 SMTP authentication: YES 22072:20171107:055224.207 Jabber notifications: YES 22072:20171107:055224.207 Ez Texting notifications: YES 22072:20171107:055224.207 ODBC: YES 22072:20171107:055224.207 SSH2 support: YES 22072:20171107:055224.207 IPv6 support: YES 22072:20171107:055224.207 TLS support: YES 22072:20171107:055224.207 ****************************** 22072:20171107:055224.207 using configuration file: /etc/zabbix/zabbix_server.conf 22072:20171107:055224.229 current database version (mandatory/optional): 03040000/03040005 22072:20171107:055224.229 required mandatory version: 03040000 22072:20171107:055224.262 server #0 started [main process] 22083:20171107:055224.287 server #8 started [discoverer #1] 22084:20171107:055224.300 server #9 started [history syncer #1] 22080:20171107:055224.301 server #5 started [housekeeper #1] 22077:20171107:055224.301 server #2 started [alerter #1] 22078:20171107:055224.302 server #3 started [alerter #2] 22079:20171107:055224.302 server #4 started [alerter #3] 22082:20171107:055224.302 server #7 started [http poller #1] 22086:20171107:055224.303 server #11 started [history syncer #3] 22076:20171107:055224.303 server #1 started [configuration syncer #1] 22081:20171107:055224.304 server #6 started [timer #1] 22085:20171107:055224.304 server #10 started [history syncer #2] 22087:20171107:055224.305 server #12 started [history syncer #4] 22089:20171107:055224.305 server #14 started [proxy poller #1] 22091:20171107:055224.310 server #16 started [task manager #1] 22093:20171107:055224.310 server #18 started [poller #2] 22095:20171107:055224.316 server #20 started [poller #4] 22090:20171107:055224.319 server #15 started [self-monitoring #1] 22092:20171107:055224.320 server #17 started [poller #1] 22094:20171107:055224.324 server #19 started [poller #3] 22096:20171107:055224.328 server #21 started [poller #5] 22088:20171107:055224.331 server #13 started [escalator #1] 22106:20171107:055224.360 server #22 started [unreachable poller #1] 22107:20171107:055224.374 server #23 started [trapper #1] 22111:20171107:055224.378 server #27 started [trapper #5] 22114:20171107:055224.382 server #30 started [preprocessing manager #1] 22114:20171107:055224.383 cannot start preprocessing service: Cannot bind socket to "/var/run/zabbix/zabbix_server_preprocessing.sock": [13] Permission denied. 22072:20171107:055224.385 One child process died (PID:22114,exitcode/signal:1). Exiting ... 22072:20171107:055226.387 syncing history data... 22072:20171107:055226.387 syncing history data done 22072:20171107:055226.387 syncing trend data... 22072:20171107:055226.387 syncing trend data done 22072:20171107:055226.387 Zabbix Server stopped. Zabbix 3.4.3 (revision 73588). 其中发现关键报错1cannot start preprocessing service: Cannot bind socket to "/var/run/zabbix/zabbix_server_preprocessing.sock": [13] Permission denied. 修复方法通过下载并导入官方支持提供的selinux模块包可以修复12345678910111213141516171819# getsebool -a | grep zabbixhttpd_can_connect_zabbix --&gt; onzabbix_can_network --&gt; off# setsebool -P zabbix_can_network on# systemctl stop mysqld# systemctl stop zabbix-server# systemctl stop zabbix-agent# yum install -y policycoreutils-python# wget -O zabbix_server_add.te https://support.zabbix.com/secure/attachment/53320/53320_zabbix_server_add.te –no-check-certificate# checkmodule -M -m -o zabbix_server_add.mod zabbix_server_add.te# semodule_package -o zabbix_server_add.pp -m zabbix_server_add.mod# semodule -i zabbix_server_add.pp# systemctl restart zabbix-server;# systemctl restart zabbix-agent# systemctl start mysqld# systemctl start zabbix-server# systemctl start zabbix-agent 参考 1.issue:https://www.zabbix.com/documentation/3.4/manual/installation/upgrade_notes_340#possible_issues_with_selinux ↩2.https://baleam.com/2017/10/zabbix-zabbix_server_alerter-sock-13-permission-denied/ ↩]]></content>
      <categories>
        <category>学习</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iTop学习笔记--REST集成]]></title>
    <url>%2F2017%2F11%2F06%2FiTop-REST%2F</url>
    <content type="text"><![CDATA[早先有同事通过直接修改iTop数据库实现集成，由于这种方式略感粗暴（一旦类对象变化或版本升级等原因导致数据库表结构变化，比较容易出现问题），所以测试了iTop官方安装文档推荐的REST/JSON集成方式，这里使用python实现。 POST参数要调用对应的action，通过下面几个参数给/webservices/rest.php Argument Description Defaut value version Version of the API. It is a way to make sure that the targetted iTop server can deliver some functionality, and it ensures stability for your scripts: as long as a version is available, the operations will remain unchanged, with the exception of the following cases: bug fixes, modification in the returned messages, new elements into the returned JSON structure. - auth_user User login - auth_pwd User password - json_data Structure containing all the information required to process your request. In particular, the requested operation is given here. callback If set, then JSON-P (JSON with padding) is used 在实际使用参数时，须要注意： 传递auth_user和auth_pwd须要在配置文件/conf/production/config-itop.php开启url 1'allowed_login_types' =&gt; 'form|basic|external|url', 所有参数整体作为dictionary传递（并做urlencode），在整个dictionary中的json_data须要事先指定为JSON类型 具体操作都是由json_data参数内完成，可以使用”operation”: “list_operations”列出所有支持的operation python实现这里测试实现了直接脚本里写了一个参数列表，POST到iTop实现ticket创建。生产环境可以通过传递相应参数来实现不通内容的传递。 1234567891011121314151617181920212223242526272829303132'''Created on Nov 6, 2017@author: edxi'''import jsonimport urllib.request, urllib.error, urllib.parsedata = dict(auth_user="admin", auth_pwd="itopadminpass", version="1.3", json_data=json.dumps(&#123; "operation": "core/create", "comment": "Synchronization from python script", "class": "UserRequest", "output_fields": "id, friendlyname", "fields": &#123; "org_id": "SELECT Organization WHERE name = \"MyOrg\"", "caller_id": &#123; "name": "xi", "first_name": "erde", &#125;, "title": "Got a problem!", "description": "It's generated by python script" &#125;&#125;))req = urllib.request.Request('http://192.168.145.130/webservices/rest.php', data=urllib.parse.urlencode(data).encode("utf-8")) # this will make the method "POST"response = urllib.request.urlopen(req)print(response.read().decode('utf-8'))]]></content>
      <categories>
        <category>学习</category>
        <category>iTop</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>iTop</tag>
        <tag>REST</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iTop学习笔记--安装和初始化配置]]></title>
    <url>%2F2017%2F10%2F24%2FiTop-initSetup%2F</url>
    <content type="text"><![CDATA[大致步骤就是按照iTop官方安装文档，过程中略有小坑，这里笔记一下。 itop相关包安装123yum install httpdyum install mysql mysql-serveryum install php php-mysql php-mcrypt php-xml php-cli php-soap php-ldap graphviz php-gd 修改上传图片大小(/etc/php.ini和/etc/my.cnf)https://wiki.openitop.org/doku.php?id=2_3_0:install:php_and_mysql_configuration 修改httpd的selinuxiTop解压到/var/www/html/itop，目录设置: 12chown -R apache:apache /var/www/html/itopchcon -R -t httpd_sys_rw_content_t /var/www/html/itop 安装向导避免mysql php mismatch报错12yum remove php-mysqlyum install php-mysqlnd 安装OPcache加速php官方文档仍旧写的是遗弃项目APC，这里改用OPcache https://laravel-china.org/topics/301/using-opcache-to-enhance-the-performance-of-the-php-55-program http://php.net/manual/zh/opcache.installation.php1yum install php-pecl-zendopcache 检查itop配置php，删除里面不需要的翻译dictionary，以免被cache（’dictionaries’ =&gt; array里） 检查mysql key cache和query cache1234show status like &apos;key_reads%&apos;; -- key_reads / key_read_requests应该小于0.1%，否则加大key_buffer_sizeshow variables like &apos;key_buffer_size&apos;;show status like &apos;Qcache%&apos;; -- mysql5.7.20开始遗弃这个功能，http://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/，mariaDB还可以用SHOW VARIABLES LIKE &apos;%query_cache%&apos;; 设置cron.php修改 /etc/itop/params 12auth_user=adminauth_pwd=adminpassword 修改 /etc/crontab 1*/1 * * * * root /usr/bin/php /var/www/html/webservices/cron.php --param_file=/etc/itop/params &gt;&gt;/var/log/itop-cron.log 2&gt;&amp;1]]></content>
      <categories>
        <category>学习</category>
        <category>iTop</category>
      </categories>
      <tags>
        <tag>iTop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible学习笔记--python编写读取excel的dynamic inventory]]></title>
    <url>%2F2017%2F10%2F10%2FAnsible-excel-inventory%2F</url>
    <content type="text"><![CDATA[Ansible提供了自己写脚本实现获取inventory的方法，直接通过github下载ansible源码，在/ansible/contrib/inventory目录里有不少现成的dynamic inventory，比如ec2、cobbler、openstack等等，可以直接从对应系统读取ansible须要管理的主机信息。这里要实现得dynamic inventory是从excel里读取主机信息（可能因为功能太low了，这么多contribute里面居然没有，于是自己写脚本实现一个）。 Dynamic Inventory介绍官方文档大致介绍了用途，这里再简单赘述一下。 Dynamic Inventory结构参照官方文档，dynamic inventory结构为一个JSON格式，里面分为分组字典和_meta字典两部分。 分组字典分组即主机列表的分组，可以包括对应分组的变量，官方示例如下： 123456789101112131415161718&#123; "databases": &#123; "hosts": ["host1.example.com", "host2.example.com"], "vars": &#123; "a": true &#125; &#125;, "webservers": ["host2.example.com", "host3.example.com"], "atlanta": &#123; "hosts": ["host1.example.com", "host4.example.com", "host5.example.com"], "vars": &#123; "b": false &#125;, "children": ["marietta", "5points"] &#125;, "marietta": ["host6.example.com"], "5points": ["host7.example.com"]&#125; 可以使用all分组存放所有其他分组或主机 _meta字典_meta字典作用是存放所有主机的变量，JSON格式如下： 12345678910111213141516&#123; # results of inventory script as above go here # ... "_meta": &#123; "hostvars": &#123; "moocow.example.com": &#123; "asdf" : 1234 &#125;, "llama.example.com": &#123; "asdf": 5678 &#125; &#125; &#125;&#125; Dynamic Inventory调用两种inventory pluginAnsible在使用Inventory时会尝试调用两种plugin，一种默认使用的ini plugin，另一种就是dynamic inventory使用的script plugin。所以在使用dynamic inventory的时候，本质上并不需要特别指定目前使用的inventory文件时ini还是一个script文件，和调用ini的inventory完全一样，用以下方式指定dynamic inventory脚本文件名即可： 命令参数方式——例如 ansible -i xl-inventory.py webserver:dbserver -m ping，命令里面直接通过-i指定xl-inventory.py这个脚本，每次调用该脚本生成JSON字典格式的inventory。 config文件——例如配置/etc/ansible/ansible.cfg文件的inventory = /etc/ansible/xl-inventory.py 环境变量——例如export ANSIBLE_INVENTORY=~/xl-inventory.py 脚本参数作为输出JSON字典的脚本，要求提供两个参数： list——用来返回整个JSON字典。 host——用来返回指定host的variable。 两个参数都是强制要求的，但是由于使用_meta已经可以为每个Host提供variable，所以这时候host实际上可以返回个空字典。 Dynamic Inventory脚本知道了dynamic inventory结构后，就编写脚本输出该JSON格式。（应该输出yaml格式也是可以的，我这里没有实际测试过） excel inventory示例这里用python写了脚本，功能是 把excel读取出来 指定某列为主机 其他列为meta的host vars 而且可以将某些列作为分组组名 组名会读取指定group vars目录对应的分组yaml文件 上面这些excel的信息通过一个ini文件指定 最终组成一个dict输出 excel表格示例如下： IP Host Name OS Version Status Function 192.168.1.10 host1 CentOS 6.9 Active ELKstack 192.168.1.11 host2.test.lab CentOS 7 Inactive ELKstack 192.168.1.12 host3.test.lab Windows 2012R2 Active ADDS 假设指定IP列为inventory的主机，OS Version、Status和Function三列都作分组，并且有ELKstack和Windows 2012R2两个group vars文件，期望结果示例JSON如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&#123; "all": &#123; "hosts": [ "192.168.1.10", "192.168.1.11", "192.168.1.12" ], "vars": &#123;&#125; &#125;, "Active": &#123; "hosts": [ "192.168.1.10", "192.168.1.12" ], "vars": &#123;&#125; &#125;, "Inactive": &#123; "hosts": [ "192.168.1.11" ], "vars": &#123;&#125; &#125;, "CentOS 6.9": &#123; "hosts": [ "192.168.1.10" ], "vars": &#123;&#125; &#125;, "CentOS 7": &#123; "hosts": [ "192.168.1.11" ], "vars": &#123;&#125; &#125;, "Windows 2012R2": &#123; "hosts": [ "192.168.1.12" ], "vars": &#123; "ansible_winrm_realm": "test.lab", "ansible_winrm_transport": "kerberos", "ansible_port": 5986, "ansible_connection": "winrm", "ansible_winrm_server_cert_validation": "ignore" &#125; &#125;, "ELKstack": &#123; "hosts": [ "192.168.1.10", "192.168.1.11" ], "vars": &#123; "proxyserver": "192.168.1.80", "proxyport": 8080, "resolv_nameservers": [ "192.168.1.12", "8.8.8.8" ] &#125; &#125;, "ADDS": &#123; "hosts": [ "192.168.1.12" ], "vars": &#123;&#125; &#125;, "_meta": &#123; "hostvars": &#123; "192.168.1.10": &#123; "IP": "192.168.1.10", "Host_Name": "host1", "OS_Version": "CentOS 6.9", "Status": "Active", "Function": "ELKstack" &#125;, "192.168.1.11": &#123; "IP": "192.168.1.11", "Host_Name": "host2.test.lab", "OS_Version": "CentOS 7", "Status": "Inactive", "Function": "ELKstack" &#125;, "192.168.1.12": &#123; "IP": "192.168.1.12", "Host_Name": "host3.test.lab", "OS_Version": "Windows 2012R2", "Status": "Active", "Function": "ADDS" &#125; &#125; &#125;&#125; 脚本程序流程 脚本代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# -*- coding: utf-8 -*-import argparseimport configparserimport jsonimport xlrdimport osimport yamldef open_excel(file): try: data = xlrd.open_workbook(file) return data except Exception as e: print(str(e))def inventory_group(ws, inventory=&#123;&#125;, host_column=0, group_column=-1): # 功能——按指定列分组主机 """ 实现——先初始化该列的hash，初始化时如该组名在group_vars_file_list里有，同时初始化vars 再逐行将主机列的值append到list里 :param ws: excel的worksheet，作为输入数据源 :param inventory: 最终要输出的inventory字典，将数据添加到该字典 :param host_column: inventory的Host或IP列号 :param group_column: 如果须要按照某列分组，提供分组使用的列号 :return: 添加excel数据后的Inventory """ if group_column == -1: inventory['all'] = &#123;'hosts': [], 'vars': &#123;&#125;&#125; for i in range(ws.nrows - 1): inventory['all']['hosts'].append(ws.cell_value(i + 1, host_column)) else: group_vars_file_list = next(os.walk(config['Excel Inventory']['group_vars_dir']))[2] for i in ws.col_values(group_column, 1): if i in group_vars_file_list: inventory[i] = &#123;'hosts': [], 'vars': yaml.load(open(config['Excel Inventory']['group_vars_dir']+'/'+i))&#125; else: inventory[i] = &#123;'hosts': [], 'vars': &#123;&#125;&#125; for i in range(ws.nrows - 1): inventory[ws.cell_value(i + 1, group_column)]['hosts'].append(ws.cell_value(i + 1, host_column)) return inventorydef ExcelInventory(): wb = xlrd.open_workbook(filename=config['Excel Inventory']['file_name']) ws = wb.sheet_by_name(config['Excel Inventory']['sheet_name']) column_hash = &#123;&#125; for i in range(ws.ncols): column_hash[ws.cell_value(0, i)] = i host_column_name = column_hash[config['Excel Inventory']['host_column_name']] # 初始化一个包括所有主机的all group # inventory_hash = &#123;ws.cell_value(0, host_column_name): &#123;'hosts': host_list, 'vars': &#123;&#125;&#125;&#125; inventory_hash = inventory_group(ws, host_column=host_column_name) # 按照Group Column例举的列分组 for item in config['Group Column']: inventory_hash = inventory_group(ws, host_column=host_column_name, group_column=column_hash[item]) # 功能——将IP对应的行的所有列作为_mata的hostvars值 # 实现——外层循环将每一行的IP作为key内层循环的hash作为value，内层循环将该列的第一行作为key当前行作为value host_list = ws.col_values(host_column_name, start_rowx=1) hostvars = &#123;&#125; for i in range(ws.nrows - 1): varscollumn = &#123;&#125; for j in range(ws.ncols): varscollumn[ws.cell_value(0, j).replace(' ', '_')] = ws.cell_value(i + 1, j) hostvars[host_list[i]] = varscollumn inventory_hash['_meta'] = &#123;'hostvars': hostvars&#125; return inventory_hashif __name__ == "__main__": parser = argparse.ArgumentParser() parser.add_argument('-l', '--list', help='hosts list', action='store_true') parser.add_argument('-H', '--host', help='hosts vars') args = vars(parser.parse_args()) config = configparser.ConfigParser() config.optionxform = str config.read('./xl-inventory.ini') if args['list']: print(json.dumps(ExcelInventory(), indent=4)) elif args['host']: print(json.dumps(&#123;'_meta': &#123;'hostvars': &#123;&#125;&#125;&#125;)) else: parser.print_help() 配置文件123456789101112[Excel Inventory]file_name = ./sample.xlsxsheet_name = Sheet1host_column_name = IPgroup_vars_dir = .# Column(s) which need to define group. Only need key. Value will be ignored.[Group Column]# List only column nameStatus =OS Version =Function = st=>start: Start|past e=>end: End op1=>operation: 从ini初始化配置|past op2=>operation: 打印帮助|current op3=>operation: 读取excel分组|current op4=>operation: 添加meta到dict|current sub1=>subroutine: 添加主机分组dict|invalid cond=>condition: 脚本参数 使用--list|approved c2=>condition: 脚本参数 使用--host|rejected c3=>condition: 主机分组 添加完成?|approved io=>inputoutput: 输出空JSON|request io2=>inputoutput: 输出dict到JSON|request st->op1(right)->cond cond(no, right)->c2 cond(yes)->op3 op3->c3 c3(no, left)->sub1 sub1(left)->op3 c3(yes)->op4->io2->e c2(yes)->io->e c2(no)->op2->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>学习</category>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible学习笔记--从Playbook创建Role]]></title>
    <url>%2F2017%2F10%2F04%2FAnsible-PlaybookToRole%2F</url>
    <content type="text"><![CDATA[下面以一个现成的playbook为例，将其内容分解并编排成一个role。 整个步骤的终端录屏 现有playbook12345678910111213141516171819202122232425262728293031323334353637383940414243- hosts: localhost sudo: true vars: baserepo: '' updatesrepo: '' extrasrepo: ''# Task setup local repositories tasks: - name: Remove repository (and clean up left-over metadata) yum_repository: name: packages state: absent notify: yum-clean-metadata - name: Add yumserver repository template: "src=yumserver.repo dest=/etc/yum.repos.d/yumserver.repo owner=root group=root mode=0644" - name: Add epel repository with proxy yum_repository: name: epel description: EPEL YUM repo proxy: "http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123; proxyport &#125;&#125;" baseurl: http://mirrors.aliyun.com/epel/7/$basearch failovermethod: priority gpgcheck: no when: proxyserver is defined and proxyport is defined and proxyserver != '' and proxyport != '' - name: Add epel repository without proxy yum_repository: name: epel description: EPEL YUM repo baseurl: http://mirrors.aliyun.com/epel/7/$basearch failovermethod: priority gpgcheck: no when: proxyserver is not defined proxyserver == '' tags: epel_repo# Handler clean yum metadata cache handlers: - name: yum-clean-metadata command: yum clean metadata args: warn: no 上面playbook的作用是设置yum repository。 除了hosts以外，大致分成三个部分： vars——指定了playbook须要用到的变量 tasks——具体playbook运行的module，具体执行了 先清理package repository并提醒handler执行metadata清理 通过template module设置的base/updates/extras repository 用yum_repository module设置epel handlers——定义了作为handler被调用的module 这里在tasks里有个template module，对应的template如下： 12345678910111213141516171819202122232425262728293031323334353637383940[base]name=CentOS-$releasever - Base&#123;% if baserepo is defined and baserepo != &apos;&apos; %&#125;baseurl=&#123;&#123; baserepo &#125;&#125;&#123;% else %&#125;mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra&#123;% endif %&#125;gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7&#123;% if proxyserver is defined and proxyserver != &apos;&apos; and proxyport is defined and baserepo == &apos;&apos; %&#125;proxy=http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123;proxyport&#125;&#125;&#123;% endif %&#125;#released updates[updates]name=CentOS-$releasever - Updates&#123;% if updatesrepo is defined and updatesrepo != &apos;&apos; %&#125;baseurl=&#123;&#123; updatesrepo &#125;&#125;&#123;% else %&#125;mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra&#123;% endif %&#125;gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7&#123;% if proxyserver is defined and proxyserver != &apos;&apos; and proxyport is defined and updatesrepo == &apos;&apos; %&#125;proxy=http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123;proxyport&#125;&#125;&#123;% endif %&#125;#additional packages that may be useful[extras]name=CentOS-$releasever - Extras&#123;% if extrasrepo is defined and extrasrepo != &apos;&apos; %&#125;baseurl=&#123;&#123; extrasrepo &#125;&#125;&#123;% else %&#125;mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra&#123;% endif %&#125;gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7&#123;% if proxyserver is defined and proxyserver != &apos;&apos; and proxyport is defined and extrasrepo == &apos;&apos; %&#125;proxy=http://&#123;&#123; proxyserver &#125;&#125;:&#123;&#123;proxyport&#125;&#125;&#123;% endif %&#125; 创建role创建目录结构role的固定目录结构如下 12345678910111213141516171819[root@ansible01 examplePlaybook]# mkdir yumrepo [root@ansible01 examplePlaybook]# # this is the role main directory[root@ansible01 examplePlaybook]# cd yumrepo[root@ansible01 yumrepo]# mkdir tasks[root@ansible01 yumrepo]# mkdir handlers[root@ansible01 yumrepo]# mkdir defaults[root@ansible01 yumrepo]# mkdir vars[root@ansible01 yumrepo]# mkdir files[root@ansible01 yumrepo]# mkdir templates[root@ansible01 yumrepo]# mkdir meta[root@ansible01 yumrepo]# lltotal 0drwxr-xr-x. 2 root root 6 Oct 4 15:47 defaultsdrwxr-xr-x. 2 root root 6 Oct 4 15:47 filesdrwxr-xr-x. 2 root root 6 Oct 4 15:47 handlersdrwxr-xr-x. 2 root root 6 Oct 4 15:47 metadrwxr-xr-x. 2 root root 6 Oct 4 15:47 tasksdrwxr-xr-x. 2 root root 6 Oct 4 15:47 templatesdrwxr-xr-x. 2 root root 6 Oct 4 15:47 vars 设置默认变量创建defaults目录里的main.yml用于设置默认变量。 在这个例子里，直接把playbook里用到的几个变量复制进去。 设置tasks创建tasks目录里的main.yml用于执行roles所调用的任务。 在这个例子里，直接把playbook里用到的几个任务复制了进去。 也可以讲不同功能的任务单独写成yml文件，然后通过在main.yml里使用include来调用（并可以使用when条件判断使用哪个任务，还可以使用tags方便在执行时调用对应功能的任务） 设置handlers创建handlers目录里的main.yml用于执行tasks所调用的handler。 在这个例子里，直接把playbook里用到的handler复制了进去。 复制template文件由于原有playbook使用到template module，所以须要把roles使用的template文件yumserver.yml复制到template目录。 测试role通过上面改写，自建的role已经完成，写一个简单的playbook用来测试 123- hosts: localhost roles: - yumrepo 执行playbook查看结果 123456789101112131415161718192021[root@ansible01 examplePlaybook]# ansible-playbook test.ymlPLAY [localhost] ******************************************************************************************************TASK [Gathering Facts] ************************************************************************************************ok: [localhost]TASK [yumrepo : Remove repository (and clean up left-over metadata)] **************************************************ok: [localhost]TASK [yumrepo : Add yumserver repository] *****************************************************************************changed: [localhost]TASK [yumrepo : Add epel repository with proxy] ***********************************************************************skipping: [localhost]TASK [yumrepo : Add epel repository without proxy] ********************************************************************ok: [localhost]PLAY RECAP ************************************************************************************************************localhost : ok=4 changed=1 unreachable=0 failed=0 可以修改测试playbook，加上参数以覆盖roles的默认参数 12345- hosts: localhost vars: baserepo: "http://repo.aliyun.com/yum/" roles: - yumrepo 再次执行就会按照上述不同的参数修改repository了。 总结大致总结下，role的目的是为了可以在各种环境下重用，把 vars, tasks, handlers等等playbook的组成元素放到固定的目录结构里。 更加详细的使用方法当然还是要参考了官方文档。 纸上得来终觉浅，绝知此事要躬行。]]></content>
      <categories>
        <category>学习</category>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿德和有米写故事--github使用案例]]></title>
    <url>%2F2017%2F08%2F31%2Fade_xiyoumi_write_story_github_example%2F</url>
    <content type="text"><![CDATA[故事梗概故事是这样滴 ade心血来潮新建了个github的repo(仓库)， 然后在repo里乱七八糟的写了点东西后提交(commit)进repo， 好奇的xiyoumi小朋友发现了这个repo，于是把repo在自己的github上做了个副本(fork)， xiyoumi小朋友把里面的东西做了点修改，也做了自己的提交， xiyoumi小朋友想把自己改的东西也合并到ade的repo里，于是提交了pull request， ade看了下pull request，觉得修改的不错，于是就合并进了repo， xiyoumi小朋友大受鼓舞，又修改了好多东西，并再次提交pull request， ade看到这次的pull request，也不知道这样改好不好，于是ade索性新建了个test分支(branch)，并在pull request里留言告诉xiyoumi，让他合并到这个分支， 于是xiyoumi小朋友重新提交了pull request，要求把合并到test分支里， ade愉快的合并了这个pull request，并且不久后把这个分支也合并进了主干(master分支)。 剧情详情好吧，具体来看看这个故事的每一段都做了点啥 ade心血来潮新建了个github的repo(仓库)， 然后在repo里乱七八糟的写了点东西后提交(commit)进repo，1234567891011121314151617[ade@~]$git init storyInitialized empty Git repository in /home/ade/story/.git/[ade@~]$cd story[ade@story]$git remote add origin git@github.com:edxi/story.git[ade@story]$echo "this is a story repository" &gt;&gt; README.md[ade@story]$git add -A[ade@story]$git commit -m "first commit"[master (root-commit) 5a98272] first commit 1 file changed, 1 insertion(+) create mode 100644 README.md[ade@story]$git push -u origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 225 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:edxi/story.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. 好奇的xiyoumi小朋友发现了这个repo，于是把repo在自己的github上做了个副本(fork)， xiyoumi小朋友把里面的东西做了点修改，也做了自己的提交，123456789101112131415161718192021222324252627282930313233[xiyoumi@~]$git clone git@github.com:xiyoumi/story.gitCloning into 'story'...remote: Counting objects: 3, done.remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0Receiving objects: 100% (3/3), done.[xiyoumi@~]$cd story/[xiyoumi@story]$echo "三只小猪的故事" &gt;&gt; pigstory.md[xiyoumi@story]$echo "xiyoumi参与写作！" &gt;&gt; README.md[xiyoumi@story]$git commit -m "交作文！"[master 13d8cc2] 交作文！ 2 files changed, 2 insertions(+) create mode 100644 pigstory.md[xiyoumi@story]$git pushwarning: push.default is unset; its implicit value is changing inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git)Counting objects: 6, done.Compressing objects: 100% (3/3), done.Writing objects: 100% (4/4), 372 bytes | 0 bytes/s, done.Total 4 (delta 0), reused 0 (delta 0)To git@github.com:xiyoumi/story.git 5a98272..13d8cc2 master -&gt; master xiyoumi小朋友想把自己改的东西也合并到ade的repo里，于是提交了pull request， ade看了下pull request，觉得修改的不错，于是就合并进了repo， xiyoumi小朋友大受鼓舞，又修改了好多东西，并再次提交pull request，1234567891011121314151617181920212223242526[xiyoumi@story]$echo "三只小猪最终打败了大灰狼" &gt;&gt; pigstory.md[xiyoumi@story]$git add -A[xiyoumi@story]$git commit -m "故事有更新啦！"[master 60ab6ec] 故事有更新啦！ 1 file changed, 1 insertion(+)[xiyoumi@story]$git pushwarning: push.default is unset; its implicit value is changing inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git)Counting objects: 5, done.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 354 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:xiyoumi/story.git 13d8cc2..60ab6ec master -&gt; master ade看到这次的pull request，也不知道这样改好不好，于是ade索性新建了个test分支(branch)，并在pull request里留言告诉xiyoumi，让他合并到这个分支里 123456[ade@story]$git push origin testCounting objects: 3, done.Writing objects: 100% (3/3), 225 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:edxi/story.git * [new branch] test -&gt; test 于是xiyoumi小朋友重新提交了pull request，要求把合并到test分支里， ade愉快的合并了这个pull request，并且不久后把这个分支也合并进了主干(master分支)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[ade@story]$git branch master* test[ade@story]$git pull origin testFrom github.com:edxi/story * branch test -&gt; FETCH_HEADUpdating 5a98272..62fe9efFast-forward README.md | 1 + pigstory.md | 2 ++ 2 files changed, 3 insertions(+) create mode 100644 pigstory.md[ade@story]$git checkout masterSwitched to branch 'master'Your branch is behind 'origin/master' by 2 commits, and can be fast-forwarded. (use "git pull" to update your local branch)[ade@story]$git pull --allFetching originUpdating 5a98272..31e542bFast-forward README.md | 1 + pigstory.md | 1 + 2 files changed, 2 insertions(+) create mode 100644 pigstory.md[ade@story]$git merge test -m "Merge branch 'test'"Merge made by the 'recursive' strategy. pigstory.md | 1 + 1 file changed, 1 insertion(+)[ade@story]$git pushwarning: push.default is unset; its implicit value is changing inGit 2.0 from 'matching' to 'simple'. To squelch this messageand maintain the current behavior after the default changes, use: git config --global push.default matchingTo squelch this message and adopt the new behavior now, use: git config --global push.default simpleSee 'git help config' and search for 'push.default' for further information.(the 'simple' mode was introduced in Git 1.7.11. Use the similar mode'current' instead of 'simple' if you sometimes use older versions of Git)Counting objects: 1, done.Writing objects: 100% (1/1), 210 bytes | 0 bytes/s, done.Total 1 (delta 0), reused 0 (delta 0)To git@github.com:edxi/story.git 31e542b..4804dda master -&gt; master 尾声到这里，已经知道了ade和xiyoumi是怎么通过github一起写故事了，可是似乎还没有这么简单，不久之后他们又有了新的问题： xiyoumi发现fork源的repo早就变了，怎么同步呢？ 随着越来越多的人加入故事投稿，分支和提交觉得乱糟糟的，怎么才能简洁点呢？能不能删除git log呢？ 问题的答案至今还不知晓~ 一个人走得快，一群人走得远 ——《有赞》广告词]]></content>
      <categories>
        <category>学习</category>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World!]]></title>
    <url>%2F2017%2F08%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[哈喽 世界！ o(￣▽￣)ブ这是DXC守护者第一篇! 简介建站故事​ 很久之后，又开始写博客了，这次用github page，觉得舒爽轻松很多。 ​ 20年前（暴露年龄），当时国内有个凯利网站空间，可以自己做网页上传，于是用FrontPage写了个html，隔天就在教室黑板上把网站链接写在黑板上得瑟。这算是自己最早的博客了。 ​ 之后就和大多数人一样，更新最多的是msn空间，msn空间关闭后迁移到wordpress，但因为被墙，于是索性自己买了域名和空间，直到2012年，付费两年后，看到自己其实多数更新都在微博上，于是也就放弃了。 ​ 现如今，就连微博都已经做过了一轮复兴之路，朋友圈和公众号是主流，但是作为老挨踢的情怀，自己偏偏又开始写起博客了，希望这个博客可以给工作生活带来帮助。 网站作用 首先，这是我的个人博客，我说是啥用就是啥用， (￣y▽￣)╭ Ohohoho….. 然后，我想肯定会记录些生活和学习上内容吧。 再就是，希望对日常工作有所帮助，也利用github这个厉害的平台，和DXC的小鬼们分享有用的资源。 还有就是，网站因为采用Hexo+github page建站，用markdown写博客，所以本站接受大家投稿。 DXC是什么​ 其实就是我现在工作的公司名字，但是就目前为止没人知道是什么缩写~(￣▽￣)”于是就有各种奇葩翻译： 稻香村——想要成为老字号的志向~ 大香肠——某个饥渴的同事翻译的。 地下城——这个我喜欢，有个古老的游戏叫做地下城守护者，也就命名了这个网站DXC守护者。 投稿指南​ 建站前只是想把github的gh-pages改善下，然后弄着弄着就索性开始建站了，后来最终选用github page+hexo作建站工具，站点内容可以使用markdown书写，可以用纯文本编辑器书写或markdown编辑器，然后非常欢迎大家上传到这个blog-contribute repository，我会定期更新到DXC守护者网站上的。 投稿格式​ 投稿接受markdown格式，可以参考资源列表里介绍的markdown编辑器来编辑（可以做work/pdf等格式的转换，但是会有部分格式损失，所以最好还是直接用markdown编辑器来书写）。具体书写方式也可以参考资源列表里列出的资源。 ​ （可选）此外由于采用hexo建站，所以还能接受下面这类格式作为页面头信息，类似于下面格式写在md文件最前面写好就可以了（参数都是可选的）： 1234567891011---title: 文章标题date: 2013/7/13 20:46:25categories:- 学习- gittags:- git- github- git page--- 这里列举了些参数： 参数 描述 默认值 title 标题 date 建立日期 文件建立日期 updated 更新日期 文件更新日期 comments 开启文章的评论功能 true tags 标签 categories 分类 description 文章描述 投稿方式​ 目前推荐下面集中方式上传.md文件： 最简单的方式是直接通过github的issues——可以直接在DXC守护者和blog-contribute这两个repo里写issue，然后把.md的内容黏贴上来，并注明这是篇需要投稿的文章，我看过后会把相应内容post到网站的。 如果想要以文件形式维护自己的文章列表，可以先fork blog-contribute这个repo，或者直接克隆repo后创建新文件，然后通过pull request的方式把md文件合并进来，后面的资源列表里有github使用的相关链接。收到新的pull request我会看过文章内容，然后合并进来，并post到网站。 当然也接受邮件寄送给我.md文件。&#x65;&#100;&#120;&#105;&#x40;&#109;&#x73;&#x6e;&#x2e;&#x63;&#111;&#109; 资源列表markdown编辑器推荐几款markdown编辑器： typora——多平台可用的编辑器，支持所见即所得的编辑，这篇就是用它写的。 Meditor.md——开源在线 Markdown 编辑器，直接在线可以编辑，所以手头没有电脑的时候，用这个写作就可以了，而且作为一个github项目，可以下载到本地，在本地使用。 iA Writer——手机上也很好用的编辑器，安卓和IOS都支持，还可以横屏编辑，搞个平板，So IBility! 另外，其实有道云笔记也很好用，也很方便在各个平台上面分享。 markdown书写 可以参考github上的markdown链接。 另外还有个的markdown cheatsheet，作为参考列表也很方便。 此外各个编辑器平台也会针对自己的帮助文档，通常会更加详细，且带有示例。 GitHub使用 个人推荐参考大V廖雪峰的官方网站。里面有浅显移动的git教程，其中包括了结合GitHub的使用方法，对入门很有帮助。 官方帮助文档当然是最全面的。]]></content>
      <categories>
        <category>学习</category>
        <category>建站</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>markdown</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
